2025-04-16 17:21:33,597 - embedding_process - INFO - === System Information ===
2025-04-16 17:21:33,597 - embedding_process - INFO - PyTorch Version: 2.6.0+cu124
2025-04-16 17:21:33,621 - embedding_process - INFO - CUDA Available: True
2025-04-16 17:21:33,622 - embedding_process - INFO - CUDA Version: 12.4
2025-04-16 17:21:33,643 - embedding_process - INFO - GPU Device: Tesla V100-SXM2-16GB
2025-04-16 17:21:33,643 - embedding_process - INFO - GPU Memory: 16.93 GB
2025-04-16 17:21:33,643 - embedding_process - INFO - NumPy Version: 2.2.4
2025-04-16 17:21:33,643 - embedding_process - INFO - OpenCV Version: 4.11.0
2025-04-16 17:21:33,643 - embedding_process - INFO - === PyTorch Data Types ===
2025-04-16 17:21:33,643 - embedding_process - INFO - BFloat16 is available in this PyTorch version
2025-04-16 17:21:33,644 - embedding_process - INFO - Dtype torch.float32 - test successful on CPU
2025-04-16 17:21:33,801 - embedding_process - INFO - Dtype torch.float32 - test successful on CUDA
2025-04-16 17:21:33,802 - embedding_process - INFO - Dtype torch.float16 - test successful on CPU
2025-04-16 17:21:33,802 - embedding_process - INFO - Dtype torch.float16 - test successful on CUDA
2025-04-16 17:21:33,802 - embedding_process - INFO - Dtype torch.float32 - test successful on CPU
2025-04-16 17:21:33,802 - embedding_process - INFO - Dtype torch.float32 - test successful on CUDA
2025-04-16 17:21:33,802 - embedding_process - INFO - Dtype torch.float64 - test successful on CPU
2025-04-16 17:21:33,802 - embedding_process - INFO - Dtype torch.float64 - test successful on CUDA
2025-04-16 17:21:33,803 - embedding_process - INFO - Dtype torch.int32 - test successful on CPU
2025-04-16 17:21:33,803 - embedding_process - INFO - Dtype torch.int32 - test successful on CUDA
2025-04-16 17:21:33,803 - embedding_process - INFO - Dtype torch.int8 - test successful on CPU
2025-04-16 17:21:33,803 - embedding_process - INFO - Dtype torch.int8 - test successful on CUDA
2025-04-16 17:21:33,803 - embedding_process - INFO - Dtype torch.int16 - test successful on CPU
2025-04-16 17:21:33,803 - embedding_process - INFO - Dtype torch.int16 - test successful on CUDA
2025-04-16 17:21:33,804 - embedding_process - INFO - Dtype torch.int32 - test successful on CPU
2025-04-16 17:21:33,804 - embedding_process - INFO - Dtype torch.int32 - test successful on CUDA
2025-04-16 17:21:33,804 - embedding_process - INFO - Dtype torch.int64 - test successful on CPU
2025-04-16 17:21:33,804 - embedding_process - INFO - Dtype torch.int64 - test successful on CUDA
2025-04-16 17:21:33,804 - embedding_process - INFO - Dtype torch.uint8 - test successful on CPU
2025-04-16 17:21:33,804 - embedding_process - INFO - Dtype torch.uint8 - test successful on CUDA
2025-04-16 17:21:33,805 - embedding_process - INFO - Dtype torch.bool - test successful on CPU
2025-04-16 17:21:33,805 - embedding_process - INFO - Dtype torch.bool - test successful on CUDA
2025-04-16 17:21:33,805 - embedding_process - INFO - Dtype torch.bfloat16 - test successful on CPU
2025-04-16 17:21:33,805 - embedding_process - INFO - Dtype torch.bfloat16 - test successful on CUDA
2025-04-16 17:21:33,805 - embedding_process - INFO - CUDA is available. Using GPU: Tesla V100-SXM2-16GB
2025-04-16 17:21:33,806 - embedding_process - INFO - Processing image: data/tesseract.png
2025-04-16 17:21:33,806 - embedding_process - INFO - Embedding models: clip, vit, resnet50
2025-04-16 17:21:33,806 - embedding_process - INFO - Using device: cuda
2025-04-16 17:21:33,806 - embedding_process - INFO - Initializing detection and segmentation pipeline...
2025-04-16 17:21:38,552 - root - INFO - Loaded checkpoint sucessfully
2025-04-16 17:21:38,984 - embedding_process - INFO - Running detection and segmentation pipeline...
2025-04-16 17:21:41,484 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-04-16 17:21:41,583 - root - INFO - Computing image embeddings for the provided image...
2025-04-16 17:21:41,860 - root - INFO - Image embeddings computed.
2025-04-16 17:21:42,431 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-04-16 17:21:42,469 - root - INFO - Computing image embeddings for the provided image...
2025-04-16 17:21:42,558 - root - INFO - Image embeddings computed.
2025-04-16 17:21:45,802 - embedding_process - INFO - Pipeline completed in 6.82 seconds
2025-04-16 17:21:45,803 - embedding_process - INFO - Initializing embedding generator with models: ['clip', 'vit', 'resnet50']
2025-04-16 17:21:48,623 - embedding_process - INFO - === Embedding Model Details ===
2025-04-16 17:21:48,623 - embedding_process - INFO - Model: ModelType.CLIP
2025-04-16 17:21:48,623 - embedding_process - INFO -   Module text_model.embeddings.token_embedding is on device cuda:0
2025-04-16 17:21:48,623 - embedding_process - INFO -   Module text_model.embeddings.position_embedding is on device cuda:0
2025-04-16 17:21:48,624 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,624 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,624 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,624 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,624 - embedding_process - INFO -   Module text_model.encoder.layers.0.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,624 - embedding_process - INFO -   Module text_model.encoder.layers.0.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,624 - embedding_process - INFO -   Module text_model.encoder.layers.0.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,625 - embedding_process - INFO -   Module text_model.encoder.layers.0.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,625 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,625 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,625 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,625 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,625 - embedding_process - INFO -   Module text_model.encoder.layers.1.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,625 - embedding_process - INFO -   Module text_model.encoder.layers.1.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,625 - embedding_process - INFO -   Module text_model.encoder.layers.1.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,625 - embedding_process - INFO -   Module text_model.encoder.layers.1.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,626 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,626 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,626 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,626 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,626 - embedding_process - INFO -   Module text_model.encoder.layers.2.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,626 - embedding_process - INFO -   Module text_model.encoder.layers.2.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,626 - embedding_process - INFO -   Module text_model.encoder.layers.2.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,626 - embedding_process - INFO -   Module text_model.encoder.layers.2.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,626 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,627 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,627 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,627 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,627 - embedding_process - INFO -   Module text_model.encoder.layers.3.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,627 - embedding_process - INFO -   Module text_model.encoder.layers.3.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,627 - embedding_process - INFO -   Module text_model.encoder.layers.3.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,627 - embedding_process - INFO -   Module text_model.encoder.layers.3.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,627 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,627 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,628 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,628 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,628 - embedding_process - INFO -   Module text_model.encoder.layers.4.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,628 - embedding_process - INFO -   Module text_model.encoder.layers.4.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,628 - embedding_process - INFO -   Module text_model.encoder.layers.4.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,628 - embedding_process - INFO -   Module text_model.encoder.layers.4.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,628 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,628 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,628 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,629 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,629 - embedding_process - INFO -   Module text_model.encoder.layers.5.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,629 - embedding_process - INFO -   Module text_model.encoder.layers.5.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,629 - embedding_process - INFO -   Module text_model.encoder.layers.5.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,629 - embedding_process - INFO -   Module text_model.encoder.layers.5.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,629 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,629 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,629 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,630 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,630 - embedding_process - INFO -   Module text_model.encoder.layers.6.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,630 - embedding_process - INFO -   Module text_model.encoder.layers.6.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,630 - embedding_process - INFO -   Module text_model.encoder.layers.6.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,630 - embedding_process - INFO -   Module text_model.encoder.layers.6.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,630 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,630 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,630 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,630 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,631 - embedding_process - INFO -   Module text_model.encoder.layers.7.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,631 - embedding_process - INFO -   Module text_model.encoder.layers.7.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,631 - embedding_process - INFO -   Module text_model.encoder.layers.7.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,631 - embedding_process - INFO -   Module text_model.encoder.layers.7.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,631 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,631 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,631 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,631 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,631 - embedding_process - INFO -   Module text_model.encoder.layers.8.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,632 - embedding_process - INFO -   Module text_model.encoder.layers.8.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,632 - embedding_process - INFO -   Module text_model.encoder.layers.8.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,632 - embedding_process - INFO -   Module text_model.encoder.layers.8.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,632 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,632 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,632 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,632 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,632 - embedding_process - INFO -   Module text_model.encoder.layers.9.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,632 - embedding_process - INFO -   Module text_model.encoder.layers.9.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,633 - embedding_process - INFO -   Module text_model.encoder.layers.9.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,633 - embedding_process - INFO -   Module text_model.encoder.layers.9.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,633 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,633 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,633 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,633 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,633 - embedding_process - INFO -   Module text_model.encoder.layers.10.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,633 - embedding_process - INFO -   Module text_model.encoder.layers.10.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,633 - embedding_process - INFO -   Module text_model.encoder.layers.10.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,634 - embedding_process - INFO -   Module text_model.encoder.layers.10.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,634 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,634 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,634 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,634 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,634 - embedding_process - INFO -   Module text_model.encoder.layers.11.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,634 - embedding_process - INFO -   Module text_model.encoder.layers.11.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,634 - embedding_process - INFO -   Module text_model.encoder.layers.11.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,635 - embedding_process - INFO -   Module text_model.encoder.layers.11.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,635 - embedding_process - INFO -   Module text_model.final_layer_norm is on device cuda:0
2025-04-16 17:21:48,635 - embedding_process - INFO -   Module vision_model.embeddings.patch_embedding is on device cuda:0
2025-04-16 17:21:48,635 - embedding_process - INFO -   Module vision_model.embeddings.position_embedding is on device cuda:0
2025-04-16 17:21:48,635 - embedding_process - INFO -   Module vision_model.pre_layrnorm is on device cuda:0
2025-04-16 17:21:48,635 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,635 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,636 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,636 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,636 - embedding_process - INFO -   Module vision_model.encoder.layers.0.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,636 - embedding_process - INFO -   Module vision_model.encoder.layers.0.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,636 - embedding_process - INFO -   Module vision_model.encoder.layers.0.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,636 - embedding_process - INFO -   Module vision_model.encoder.layers.0.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,636 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,637 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,637 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,637 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,637 - embedding_process - INFO -   Module vision_model.encoder.layers.1.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,637 - embedding_process - INFO -   Module vision_model.encoder.layers.1.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,637 - embedding_process - INFO -   Module vision_model.encoder.layers.1.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,637 - embedding_process - INFO -   Module vision_model.encoder.layers.1.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,638 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,638 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,638 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,638 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,638 - embedding_process - INFO -   Module vision_model.encoder.layers.2.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,638 - embedding_process - INFO -   Module vision_model.encoder.layers.2.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,638 - embedding_process - INFO -   Module vision_model.encoder.layers.2.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,639 - embedding_process - INFO -   Module vision_model.encoder.layers.2.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,639 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,639 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,639 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,639 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,639 - embedding_process - INFO -   Module vision_model.encoder.layers.3.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,639 - embedding_process - INFO -   Module vision_model.encoder.layers.3.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,640 - embedding_process - INFO -   Module vision_model.encoder.layers.3.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,640 - embedding_process - INFO -   Module vision_model.encoder.layers.3.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,640 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,640 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,640 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,640 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,640 - embedding_process - INFO -   Module vision_model.encoder.layers.4.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,640 - embedding_process - INFO -   Module vision_model.encoder.layers.4.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,641 - embedding_process - INFO -   Module vision_model.encoder.layers.4.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,641 - embedding_process - INFO -   Module vision_model.encoder.layers.4.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,641 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,641 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,641 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,641 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,641 - embedding_process - INFO -   Module vision_model.encoder.layers.5.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,642 - embedding_process - INFO -   Module vision_model.encoder.layers.5.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,642 - embedding_process - INFO -   Module vision_model.encoder.layers.5.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,642 - embedding_process - INFO -   Module vision_model.encoder.layers.5.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,642 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,642 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,642 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,642 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,642 - embedding_process - INFO -   Module vision_model.encoder.layers.6.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,643 - embedding_process - INFO -   Module vision_model.encoder.layers.6.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,643 - embedding_process - INFO -   Module vision_model.encoder.layers.6.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,643 - embedding_process - INFO -   Module vision_model.encoder.layers.6.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,643 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,643 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,643 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,643 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,644 - embedding_process - INFO -   Module vision_model.encoder.layers.7.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,644 - embedding_process - INFO -   Module vision_model.encoder.layers.7.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,644 - embedding_process - INFO -   Module vision_model.encoder.layers.7.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,644 - embedding_process - INFO -   Module vision_model.encoder.layers.7.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,644 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,644 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,644 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,645 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,645 - embedding_process - INFO -   Module vision_model.encoder.layers.8.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,645 - embedding_process - INFO -   Module vision_model.encoder.layers.8.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,645 - embedding_process - INFO -   Module vision_model.encoder.layers.8.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,645 - embedding_process - INFO -   Module vision_model.encoder.layers.8.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,645 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,645 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,646 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,646 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,646 - embedding_process - INFO -   Module vision_model.encoder.layers.9.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,646 - embedding_process - INFO -   Module vision_model.encoder.layers.9.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,646 - embedding_process - INFO -   Module vision_model.encoder.layers.9.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,646 - embedding_process - INFO -   Module vision_model.encoder.layers.9.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,646 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,646 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,647 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,647 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,647 - embedding_process - INFO -   Module vision_model.encoder.layers.10.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,647 - embedding_process - INFO -   Module vision_model.encoder.layers.10.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,647 - embedding_process - INFO -   Module vision_model.encoder.layers.10.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,647 - embedding_process - INFO -   Module vision_model.encoder.layers.10.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,647 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.k_proj is on device cuda:0
2025-04-16 17:21:48,648 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.v_proj is on device cuda:0
2025-04-16 17:21:48,648 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.q_proj is on device cuda:0
2025-04-16 17:21:48,648 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.out_proj is on device cuda:0
2025-04-16 17:21:48,648 - embedding_process - INFO -   Module vision_model.encoder.layers.11.layer_norm1 is on device cuda:0
2025-04-16 17:21:48,648 - embedding_process - INFO -   Module vision_model.encoder.layers.11.mlp.fc1 is on device cuda:0
2025-04-16 17:21:48,648 - embedding_process - INFO -   Module vision_model.encoder.layers.11.mlp.fc2 is on device cuda:0
2025-04-16 17:21:48,648 - embedding_process - INFO -   Module vision_model.encoder.layers.11.layer_norm2 is on device cuda:0
2025-04-16 17:21:48,648 - embedding_process - INFO -   Module vision_model.post_layernorm is on device cuda:0
2025-04-16 17:21:48,649 - embedding_process - INFO -   Module visual_projection is on device cuda:0
2025-04-16 17:21:48,649 - embedding_process - INFO -   Module text_projection is on device cuda:0
2025-04-16 17:21:48,649 - embedding_process - INFO - Model: ModelType.VIT
2025-04-16 17:21:48,649 - embedding_process - INFO -   Module embeddings.patch_embeddings.projection is on device cuda:0
2025-04-16 17:21:48,649 - embedding_process - INFO -   Module encoder.layer.0.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,649 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,650 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,650 - embedding_process - INFO -   Module encoder.layer.0.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,650 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,650 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,650 - embedding_process - INFO -   Module encoder.layer.0.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,650 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,650 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,650 - embedding_process - INFO -   Module encoder.layer.0.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,651 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,651 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,651 - embedding_process - INFO -   Module encoder.layer.0.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,651 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,651 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,651 - embedding_process - INFO -   Module encoder.layer.0.output.dense is on device cuda:0
2025-04-16 17:21:48,651 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,651 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,652 - embedding_process - INFO -   Module encoder.layer.0.layernorm_before is on device cuda:0
2025-04-16 17:21:48,652 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,652 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,652 - embedding_process - INFO -   Module encoder.layer.0.layernorm_after is on device cuda:0
2025-04-16 17:21:48,652 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,652 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,652 - embedding_process - INFO -   Module encoder.layer.1.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,652 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,653 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,653 - embedding_process - INFO -   Module encoder.layer.1.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,653 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,653 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,653 - embedding_process - INFO -   Module encoder.layer.1.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,653 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,653 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,654 - embedding_process - INFO -   Module encoder.layer.1.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,654 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,654 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,654 - embedding_process - INFO -   Module encoder.layer.1.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,654 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,654 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,654 - embedding_process - INFO -   Module encoder.layer.1.output.dense is on device cuda:0
2025-04-16 17:21:48,655 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,655 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,655 - embedding_process - INFO -   Module encoder.layer.1.layernorm_before is on device cuda:0
2025-04-16 17:21:48,655 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,655 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,655 - embedding_process - INFO -   Module encoder.layer.1.layernorm_after is on device cuda:0
2025-04-16 17:21:48,655 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,655 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,656 - embedding_process - INFO -   Module encoder.layer.2.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,656 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,656 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,656 - embedding_process - INFO -   Module encoder.layer.2.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,656 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,656 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,656 - embedding_process - INFO -   Module encoder.layer.2.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,656 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,657 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,657 - embedding_process - INFO -   Module encoder.layer.2.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,657 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,657 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,657 - embedding_process - INFO -   Module encoder.layer.2.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,657 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,657 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,658 - embedding_process - INFO -   Module encoder.layer.2.output.dense is on device cuda:0
2025-04-16 17:21:48,658 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,658 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,658 - embedding_process - INFO -   Module encoder.layer.2.layernorm_before is on device cuda:0
2025-04-16 17:21:48,658 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,658 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,658 - embedding_process - INFO -   Module encoder.layer.2.layernorm_after is on device cuda:0
2025-04-16 17:21:48,659 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,659 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,659 - embedding_process - INFO -   Module encoder.layer.3.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,659 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,659 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,659 - embedding_process - INFO -   Module encoder.layer.3.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,659 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,659 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,660 - embedding_process - INFO -   Module encoder.layer.3.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,660 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,660 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,660 - embedding_process - INFO -   Module encoder.layer.3.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,660 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,660 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,660 - embedding_process - INFO -   Module encoder.layer.3.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,660 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,661 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,661 - embedding_process - INFO -   Module encoder.layer.3.output.dense is on device cuda:0
2025-04-16 17:21:48,661 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,661 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,661 - embedding_process - INFO -   Module encoder.layer.3.layernorm_before is on device cuda:0
2025-04-16 17:21:48,661 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,661 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,661 - embedding_process - INFO -   Module encoder.layer.3.layernorm_after is on device cuda:0
2025-04-16 17:21:48,662 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,662 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,662 - embedding_process - INFO -   Module encoder.layer.4.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,662 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,662 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,662 - embedding_process - INFO -   Module encoder.layer.4.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,662 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,663 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,663 - embedding_process - INFO -   Module encoder.layer.4.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,663 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,663 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,663 - embedding_process - INFO -   Module encoder.layer.4.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,663 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,663 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,663 - embedding_process - INFO -   Module encoder.layer.4.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,664 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,664 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,664 - embedding_process - INFO -   Module encoder.layer.4.output.dense is on device cuda:0
2025-04-16 17:21:48,664 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,664 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,664 - embedding_process - INFO -   Module encoder.layer.4.layernorm_before is on device cuda:0
2025-04-16 17:21:48,664 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,665 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,665 - embedding_process - INFO -   Module encoder.layer.4.layernorm_after is on device cuda:0
2025-04-16 17:21:48,665 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,665 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,665 - embedding_process - INFO -   Module encoder.layer.5.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,665 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,665 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,665 - embedding_process - INFO -   Module encoder.layer.5.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,666 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,666 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,666 - embedding_process - INFO -   Module encoder.layer.5.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,666 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,666 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,666 - embedding_process - INFO -   Module encoder.layer.5.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,666 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,666 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,667 - embedding_process - INFO -   Module encoder.layer.5.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,667 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,667 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,667 - embedding_process - INFO -   Module encoder.layer.5.output.dense is on device cuda:0
2025-04-16 17:21:48,667 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,667 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,667 - embedding_process - INFO -   Module encoder.layer.5.layernorm_before is on device cuda:0
2025-04-16 17:21:48,668 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,668 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,668 - embedding_process - INFO -   Module encoder.layer.5.layernorm_after is on device cuda:0
2025-04-16 17:21:48,668 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,668 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,668 - embedding_process - INFO -   Module encoder.layer.6.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,668 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,669 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,669 - embedding_process - INFO -   Module encoder.layer.6.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,669 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,669 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,669 - embedding_process - INFO -   Module encoder.layer.6.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,669 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,669 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,669 - embedding_process - INFO -   Module encoder.layer.6.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,670 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,670 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,670 - embedding_process - INFO -   Module encoder.layer.6.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,670 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,670 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,670 - embedding_process - INFO -   Module encoder.layer.6.output.dense is on device cuda:0
2025-04-16 17:21:48,670 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,670 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,671 - embedding_process - INFO -   Module encoder.layer.6.layernorm_before is on device cuda:0
2025-04-16 17:21:48,671 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,671 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,671 - embedding_process - INFO -   Module encoder.layer.6.layernorm_after is on device cuda:0
2025-04-16 17:21:48,671 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,671 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,671 - embedding_process - INFO -   Module encoder.layer.7.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,672 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,672 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,672 - embedding_process - INFO -   Module encoder.layer.7.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,672 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,672 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,672 - embedding_process - INFO -   Module encoder.layer.7.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,672 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,672 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,673 - embedding_process - INFO -   Module encoder.layer.7.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,673 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,673 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,673 - embedding_process - INFO -   Module encoder.layer.7.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,673 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,673 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,673 - embedding_process - INFO -   Module encoder.layer.7.output.dense is on device cuda:0
2025-04-16 17:21:48,674 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,674 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,674 - embedding_process - INFO -   Module encoder.layer.7.layernorm_before is on device cuda:0
2025-04-16 17:21:48,674 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,674 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,674 - embedding_process - INFO -   Module encoder.layer.7.layernorm_after is on device cuda:0
2025-04-16 17:21:48,674 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,674 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,675 - embedding_process - INFO -   Module encoder.layer.8.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,675 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,675 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,675 - embedding_process - INFO -   Module encoder.layer.8.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,675 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,675 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,675 - embedding_process - INFO -   Module encoder.layer.8.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,676 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,676 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,676 - embedding_process - INFO -   Module encoder.layer.8.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,676 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,676 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,676 - embedding_process - INFO -   Module encoder.layer.8.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,676 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,676 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,677 - embedding_process - INFO -   Module encoder.layer.8.output.dense is on device cuda:0
2025-04-16 17:21:48,677 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,677 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,677 - embedding_process - INFO -   Module encoder.layer.8.layernorm_before is on device cuda:0
2025-04-16 17:21:48,677 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,677 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,677 - embedding_process - INFO -   Module encoder.layer.8.layernorm_after is on device cuda:0
2025-04-16 17:21:48,677 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,678 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,678 - embedding_process - INFO -   Module encoder.layer.9.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,678 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,678 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,678 - embedding_process - INFO -   Module encoder.layer.9.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,678 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,678 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,679 - embedding_process - INFO -   Module encoder.layer.9.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,679 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,679 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,679 - embedding_process - INFO -   Module encoder.layer.9.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,679 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,679 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,679 - embedding_process - INFO -   Module encoder.layer.9.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,680 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,680 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,680 - embedding_process - INFO -   Module encoder.layer.9.output.dense is on device cuda:0
2025-04-16 17:21:48,680 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,680 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,680 - embedding_process - INFO -   Module encoder.layer.9.layernorm_before is on device cuda:0
2025-04-16 17:21:48,680 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,680 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,681 - embedding_process - INFO -   Module encoder.layer.9.layernorm_after is on device cuda:0
2025-04-16 17:21:48,681 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,681 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,681 - embedding_process - INFO -   Module encoder.layer.10.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,681 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,681 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,681 - embedding_process - INFO -   Module encoder.layer.10.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,682 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,682 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,682 - embedding_process - INFO -   Module encoder.layer.10.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,682 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,682 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,682 - embedding_process - INFO -   Module encoder.layer.10.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,682 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,682 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,683 - embedding_process - INFO -   Module encoder.layer.10.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,683 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,683 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,683 - embedding_process - INFO -   Module encoder.layer.10.output.dense is on device cuda:0
2025-04-16 17:21:48,683 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,683 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,683 - embedding_process - INFO -   Module encoder.layer.10.layernorm_before is on device cuda:0
2025-04-16 17:21:48,684 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,684 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,684 - embedding_process - INFO -   Module encoder.layer.10.layernorm_after is on device cuda:0
2025-04-16 17:21:48,684 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,684 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,684 - embedding_process - INFO -   Module encoder.layer.11.attention.attention.query is on device cuda:0
2025-04-16 17:21:48,684 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,685 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,685 - embedding_process - INFO -   Module encoder.layer.11.attention.attention.key is on device cuda:0
2025-04-16 17:21:48,685 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,685 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,685 - embedding_process - INFO -   Module encoder.layer.11.attention.attention.value is on device cuda:0
2025-04-16 17:21:48,685 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,685 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,685 - embedding_process - INFO -   Module encoder.layer.11.attention.output.dense is on device cuda:0
2025-04-16 17:21:48,685 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:21:48,686 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,686 - embedding_process - INFO -   Module encoder.layer.11.intermediate.dense is on device cuda:0
2025-04-16 17:21:48,686 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:21:48,686 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:21:48,686 - embedding_process - INFO -   Module encoder.layer.11.output.dense is on device cuda:0
2025-04-16 17:21:48,686 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:21:48,686 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,686 - embedding_process - INFO -   Module encoder.layer.11.layernorm_before is on device cuda:0
2025-04-16 17:21:48,686 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,686 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,686 - embedding_process - INFO -   Module encoder.layer.11.layernorm_after is on device cuda:0
2025-04-16 17:21:48,687 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,687 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:21:48,687 - embedding_process - INFO -   Module layernorm is on device cuda:0
2025-04-16 17:21:48,687 - embedding_process - INFO -   Module pooler.dense is on device cuda:0
2025-04-16 17:21:48,687 - embedding_process - INFO - Model: ModelType.RESNET50
2025-04-16 17:21:48,687 - embedding_process - INFO -   Module 0 is on device cuda:0
2025-04-16 17:21:48,687 - embedding_process - INFO -   Weight - Shape: torch.Size([64, 3, 7, 7]), Type: torch.float32
2025-04-16 17:21:48,687 - embedding_process - INFO -   Module 1 is on device cuda:0
2025-04-16 17:21:48,687 - embedding_process - INFO -   Weight - Shape: torch.Size([64]), Type: torch.float32
2025-04-16 17:21:48,688 - embedding_process - INFO -   Bias - Shape: torch.Size([64]), Type: torch.float32
2025-04-16 17:21:48,688 - embedding_process - INFO -   Module 4.0.conv1 is on device cuda:0
2025-04-16 17:21:48,688 - embedding_process - INFO -   Module 4.0.bn1 is on device cuda:0
2025-04-16 17:21:48,688 - embedding_process - INFO -   Module 4.0.conv2 is on device cuda:0
2025-04-16 17:21:48,688 - embedding_process - INFO -   Module 4.0.bn2 is on device cuda:0
2025-04-16 17:21:48,688 - embedding_process - INFO -   Module 4.0.conv3 is on device cuda:0
2025-04-16 17:21:48,688 - embedding_process - INFO -   Module 4.0.bn3 is on device cuda:0
2025-04-16 17:21:48,688 - embedding_process - INFO -   Module 4.0.downsample.0 is on device cuda:0
2025-04-16 17:21:48,689 - embedding_process - INFO -   Module 4.0.downsample.1 is on device cuda:0
2025-04-16 17:21:48,689 - embedding_process - INFO -   Module 4.1.conv1 is on device cuda:0
2025-04-16 17:21:48,689 - embedding_process - INFO -   Module 4.1.bn1 is on device cuda:0
2025-04-16 17:21:48,689 - embedding_process - INFO -   Module 4.1.conv2 is on device cuda:0
2025-04-16 17:21:48,689 - embedding_process - INFO -   Module 4.1.bn2 is on device cuda:0
2025-04-16 17:21:48,689 - embedding_process - INFO -   Module 4.1.conv3 is on device cuda:0
2025-04-16 17:21:48,689 - embedding_process - INFO -   Module 4.1.bn3 is on device cuda:0
2025-04-16 17:21:48,690 - embedding_process - INFO -   Module 4.2.conv1 is on device cuda:0
2025-04-16 17:21:48,690 - embedding_process - INFO -   Module 4.2.bn1 is on device cuda:0
2025-04-16 17:21:48,690 - embedding_process - INFO -   Module 4.2.conv2 is on device cuda:0
2025-04-16 17:21:48,690 - embedding_process - INFO -   Module 4.2.bn2 is on device cuda:0
2025-04-16 17:21:48,690 - embedding_process - INFO -   Module 4.2.conv3 is on device cuda:0
2025-04-16 17:21:48,690 - embedding_process - INFO -   Module 4.2.bn3 is on device cuda:0
2025-04-16 17:21:48,690 - embedding_process - INFO -   Module 5.0.conv1 is on device cuda:0
2025-04-16 17:21:48,691 - embedding_process - INFO -   Module 5.0.bn1 is on device cuda:0
2025-04-16 17:21:48,691 - embedding_process - INFO -   Module 5.0.conv2 is on device cuda:0
2025-04-16 17:21:48,691 - embedding_process - INFO -   Module 5.0.bn2 is on device cuda:0
2025-04-16 17:21:48,691 - embedding_process - INFO -   Module 5.0.conv3 is on device cuda:0
2025-04-16 17:21:48,691 - embedding_process - INFO -   Module 5.0.bn3 is on device cuda:0
2025-04-16 17:21:48,691 - embedding_process - INFO -   Module 5.0.downsample.0 is on device cuda:0
2025-04-16 17:21:48,691 - embedding_process - INFO -   Module 5.0.downsample.1 is on device cuda:0
2025-04-16 17:21:48,692 - embedding_process - INFO -   Module 5.1.conv1 is on device cuda:0
2025-04-16 17:21:48,692 - embedding_process - INFO -   Module 5.1.bn1 is on device cuda:0
2025-04-16 17:21:48,692 - embedding_process - INFO -   Module 5.1.conv2 is on device cuda:0
2025-04-16 17:21:48,692 - embedding_process - INFO -   Module 5.1.bn2 is on device cuda:0
2025-04-16 17:21:48,692 - embedding_process - INFO -   Module 5.1.conv3 is on device cuda:0
2025-04-16 17:21:48,692 - embedding_process - INFO -   Module 5.1.bn3 is on device cuda:0
2025-04-16 17:21:48,692 - embedding_process - INFO -   Module 5.2.conv1 is on device cuda:0
2025-04-16 17:21:48,692 - embedding_process - INFO -   Module 5.2.bn1 is on device cuda:0
2025-04-16 17:21:48,693 - embedding_process - INFO -   Module 5.2.conv2 is on device cuda:0
2025-04-16 17:21:48,693 - embedding_process - INFO -   Module 5.2.bn2 is on device cuda:0
2025-04-16 17:21:48,693 - embedding_process - INFO -   Module 5.2.conv3 is on device cuda:0
2025-04-16 17:21:48,693 - embedding_process - INFO -   Module 5.2.bn3 is on device cuda:0
2025-04-16 17:21:48,693 - embedding_process - INFO -   Module 5.3.conv1 is on device cuda:0
2025-04-16 17:21:48,693 - embedding_process - INFO -   Module 5.3.bn1 is on device cuda:0
2025-04-16 17:21:48,693 - embedding_process - INFO -   Module 5.3.conv2 is on device cuda:0
2025-04-16 17:21:48,694 - embedding_process - INFO -   Module 5.3.bn2 is on device cuda:0
2025-04-16 17:21:48,694 - embedding_process - INFO -   Module 5.3.conv3 is on device cuda:0
2025-04-16 17:21:48,694 - embedding_process - INFO -   Module 5.3.bn3 is on device cuda:0
2025-04-16 17:21:48,694 - embedding_process - INFO -   Module 6.0.conv1 is on device cuda:0
2025-04-16 17:21:48,694 - embedding_process - INFO -   Module 6.0.bn1 is on device cuda:0
2025-04-16 17:21:48,694 - embedding_process - INFO -   Module 6.0.conv2 is on device cuda:0
2025-04-16 17:21:48,694 - embedding_process - INFO -   Module 6.0.bn2 is on device cuda:0
2025-04-16 17:21:48,695 - embedding_process - INFO -   Module 6.0.conv3 is on device cuda:0
2025-04-16 17:21:48,695 - embedding_process - INFO -   Module 6.0.bn3 is on device cuda:0
2025-04-16 17:21:48,695 - embedding_process - INFO -   Module 6.0.downsample.0 is on device cuda:0
2025-04-16 17:21:48,695 - embedding_process - INFO -   Module 6.0.downsample.1 is on device cuda:0
2025-04-16 17:21:48,695 - embedding_process - INFO -   Module 6.1.conv1 is on device cuda:0
2025-04-16 17:21:48,695 - embedding_process - INFO -   Module 6.1.bn1 is on device cuda:0
2025-04-16 17:21:48,695 - embedding_process - INFO -   Module 6.1.conv2 is on device cuda:0
2025-04-16 17:21:48,695 - embedding_process - INFO -   Module 6.1.bn2 is on device cuda:0
2025-04-16 17:21:48,696 - embedding_process - INFO -   Module 6.1.conv3 is on device cuda:0
2025-04-16 17:21:48,696 - embedding_process - INFO -   Module 6.1.bn3 is on device cuda:0
2025-04-16 17:21:48,696 - embedding_process - INFO -   Module 6.2.conv1 is on device cuda:0
2025-04-16 17:21:48,696 - embedding_process - INFO -   Module 6.2.bn1 is on device cuda:0
2025-04-16 17:21:48,696 - embedding_process - INFO -   Module 6.2.conv2 is on device cuda:0
2025-04-16 17:21:48,696 - embedding_process - INFO -   Module 6.2.bn2 is on device cuda:0
2025-04-16 17:21:48,696 - embedding_process - INFO -   Module 6.2.conv3 is on device cuda:0
2025-04-16 17:21:48,697 - embedding_process - INFO -   Module 6.2.bn3 is on device cuda:0
2025-04-16 17:21:48,697 - embedding_process - INFO -   Module 6.3.conv1 is on device cuda:0
2025-04-16 17:21:48,697 - embedding_process - INFO -   Module 6.3.bn1 is on device cuda:0
2025-04-16 17:21:48,697 - embedding_process - INFO -   Module 6.3.conv2 is on device cuda:0
2025-04-16 17:21:48,697 - embedding_process - INFO -   Module 6.3.bn2 is on device cuda:0
2025-04-16 17:21:48,697 - embedding_process - INFO -   Module 6.3.conv3 is on device cuda:0
2025-04-16 17:21:48,697 - embedding_process - INFO -   Module 6.3.bn3 is on device cuda:0
2025-04-16 17:21:48,697 - embedding_process - INFO -   Module 6.4.conv1 is on device cuda:0
2025-04-16 17:21:48,698 - embedding_process - INFO -   Module 6.4.bn1 is on device cuda:0
2025-04-16 17:21:48,698 - embedding_process - INFO -   Module 6.4.conv2 is on device cuda:0
2025-04-16 17:21:48,698 - embedding_process - INFO -   Module 6.4.bn2 is on device cuda:0
2025-04-16 17:21:48,698 - embedding_process - INFO -   Module 6.4.conv3 is on device cuda:0
2025-04-16 17:21:48,698 - embedding_process - INFO -   Module 6.4.bn3 is on device cuda:0
2025-04-16 17:21:48,698 - embedding_process - INFO -   Module 6.5.conv1 is on device cuda:0
2025-04-16 17:21:48,698 - embedding_process - INFO -   Module 6.5.bn1 is on device cuda:0
2025-04-16 17:21:48,699 - embedding_process - INFO -   Module 6.5.conv2 is on device cuda:0
2025-04-16 17:21:48,699 - embedding_process - INFO -   Module 6.5.bn2 is on device cuda:0
2025-04-16 17:21:48,699 - embedding_process - INFO -   Module 6.5.conv3 is on device cuda:0
2025-04-16 17:21:48,699 - embedding_process - INFO -   Module 6.5.bn3 is on device cuda:0
2025-04-16 17:21:48,699 - embedding_process - INFO -   Module 7.0.conv1 is on device cuda:0
2025-04-16 17:21:48,699 - embedding_process - INFO -   Module 7.0.bn1 is on device cuda:0
2025-04-16 17:21:48,699 - embedding_process - INFO -   Module 7.0.conv2 is on device cuda:0
2025-04-16 17:21:48,700 - embedding_process - INFO -   Module 7.0.bn2 is on device cuda:0
2025-04-16 17:21:48,700 - embedding_process - INFO -   Module 7.0.conv3 is on device cuda:0
2025-04-16 17:21:48,700 - embedding_process - INFO -   Module 7.0.bn3 is on device cuda:0
2025-04-16 17:21:48,700 - embedding_process - INFO -   Module 7.0.downsample.0 is on device cuda:0
2025-04-16 17:21:48,700 - embedding_process - INFO -   Module 7.0.downsample.1 is on device cuda:0
2025-04-16 17:21:48,700 - embedding_process - INFO -   Module 7.1.conv1 is on device cuda:0
2025-04-16 17:21:48,701 - embedding_process - INFO -   Module 7.1.bn1 is on device cuda:0
2025-04-16 17:21:48,701 - embedding_process - INFO -   Module 7.1.conv2 is on device cuda:0
2025-04-16 17:21:48,701 - embedding_process - INFO -   Module 7.1.bn2 is on device cuda:0
2025-04-16 17:21:48,701 - embedding_process - INFO -   Module 7.1.conv3 is on device cuda:0
2025-04-16 17:21:48,701 - embedding_process - INFO -   Module 7.1.bn3 is on device cuda:0
2025-04-16 17:21:48,701 - embedding_process - INFO -   Module 7.2.conv1 is on device cuda:0
2025-04-16 17:21:48,701 - embedding_process - INFO -   Module 7.2.bn1 is on device cuda:0
2025-04-16 17:21:48,701 - embedding_process - INFO -   Module 7.2.conv2 is on device cuda:0
2025-04-16 17:21:48,702 - embedding_process - INFO -   Module 7.2.bn2 is on device cuda:0
2025-04-16 17:21:48,702 - embedding_process - INFO -   Module 7.2.conv3 is on device cuda:0
2025-04-16 17:21:48,702 - embedding_process - INFO -   Module 7.2.bn3 is on device cuda:0
2025-04-16 17:21:48,702 - embedding_process - INFO - Loading original image: data/tesseract.png
2025-04-16 17:21:48,715 - embedding_process - INFO - Original image shape: (453, 908, 3), dtype: uint8
2025-04-16 17:21:48,715 - embedding_process - INFO - Found 36 detections in the image
2025-04-16 17:21:48,715 - embedding_process - INFO - Generating embeddings for detections...
2025-04-16 17:21:48,715 - embedding_process - INFO - 
Processing detection 1/36: tesseract_0_00_0.00
2025-04-16 17:21:48,735 - embedding_process - INFO - Generating embeddings for detection tesseract_0_00_0.00...
2025-04-16 17:21:48,735 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:21:48,769 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:21:48,769 - embedding_process - ERROR - Error: cannot access local variable 'traceback' where it is not associated with a value
2025-04-16 17:21:48,771 - embedding_process - ERROR - Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 395, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 434, in main
    logger.error(f"    Traceback: {traceback.format_exc()}")
                                   ^^^^^^^^^
UnboundLocalError: cannot access local variable 'traceback' where it is not associated with a value

2025-04-16 17:21:48,771 - embedding_process - ERROR - 
Execution failed after 15.18 seconds
2025-04-16 17:21:48,771 - embedding_process - ERROR - Processed 1 images with 36 detections
2025-04-16 17:24:45,732 - embedding_process - INFO - === System Information ===
2025-04-16 17:24:45,732 - embedding_process - INFO - PyTorch Version: 2.6.0+cu124
2025-04-16 17:24:45,756 - embedding_process - INFO - CUDA Available: True
2025-04-16 17:24:45,756 - embedding_process - INFO - CUDA Version: 12.4
2025-04-16 17:24:45,777 - embedding_process - INFO - GPU Device: Tesla V100-SXM2-16GB
2025-04-16 17:24:45,777 - embedding_process - INFO - GPU Memory: 16.93 GB
2025-04-16 17:24:45,777 - embedding_process - INFO - NumPy Version: 2.2.4
2025-04-16 17:24:45,777 - embedding_process - INFO - OpenCV Version: 4.11.0
2025-04-16 17:24:45,777 - embedding_process - INFO - === PyTorch Data Types ===
2025-04-16 17:24:45,778 - embedding_process - INFO - BFloat16 is available in this PyTorch version
2025-04-16 17:24:45,778 - embedding_process - INFO - Dtype torch.float32 - test successful on CPU
2025-04-16 17:24:45,938 - embedding_process - INFO - Dtype torch.float32 - test successful on CUDA
2025-04-16 17:24:45,939 - embedding_process - INFO - Dtype torch.float16 - test successful on CPU
2025-04-16 17:24:45,939 - embedding_process - INFO - Dtype torch.float16 - test successful on CUDA
2025-04-16 17:24:45,939 - embedding_process - INFO - Dtype torch.float32 - test successful on CPU
2025-04-16 17:24:45,939 - embedding_process - INFO - Dtype torch.float32 - test successful on CUDA
2025-04-16 17:24:45,939 - embedding_process - INFO - Dtype torch.float64 - test successful on CPU
2025-04-16 17:24:45,940 - embedding_process - INFO - Dtype torch.float64 - test successful on CUDA
2025-04-16 17:24:45,940 - embedding_process - INFO - Dtype torch.int32 - test successful on CPU
2025-04-16 17:24:45,940 - embedding_process - INFO - Dtype torch.int32 - test successful on CUDA
2025-04-16 17:24:45,940 - embedding_process - INFO - Dtype torch.int8 - test successful on CPU
2025-04-16 17:24:45,940 - embedding_process - INFO - Dtype torch.int8 - test successful on CUDA
2025-04-16 17:24:45,940 - embedding_process - INFO - Dtype torch.int16 - test successful on CPU
2025-04-16 17:24:45,941 - embedding_process - INFO - Dtype torch.int16 - test successful on CUDA
2025-04-16 17:24:45,941 - embedding_process - INFO - Dtype torch.int32 - test successful on CPU
2025-04-16 17:24:45,941 - embedding_process - INFO - Dtype torch.int32 - test successful on CUDA
2025-04-16 17:24:45,941 - embedding_process - INFO - Dtype torch.int64 - test successful on CPU
2025-04-16 17:24:45,941 - embedding_process - INFO - Dtype torch.int64 - test successful on CUDA
2025-04-16 17:24:45,941 - embedding_process - INFO - Dtype torch.uint8 - test successful on CPU
2025-04-16 17:24:45,942 - embedding_process - INFO - Dtype torch.uint8 - test successful on CUDA
2025-04-16 17:24:45,942 - embedding_process - INFO - Dtype torch.bool - test successful on CPU
2025-04-16 17:24:45,942 - embedding_process - INFO - Dtype torch.bool - test successful on CUDA
2025-04-16 17:24:45,942 - embedding_process - INFO - Dtype torch.bfloat16 - test successful on CPU
2025-04-16 17:24:45,942 - embedding_process - INFO - Dtype torch.bfloat16 - test successful on CUDA
2025-04-16 17:24:45,942 - embedding_process - INFO - CUDA is available. Using GPU: Tesla V100-SXM2-16GB
2025-04-16 17:24:45,942 - embedding_process - INFO - Processing image: data/tesseract.png
2025-04-16 17:24:45,942 - embedding_process - INFO - Embedding models: clip, vit, resnet50
2025-04-16 17:24:45,943 - embedding_process - INFO - Using device: cuda
2025-04-16 17:24:45,943 - embedding_process - INFO - Initializing detection and segmentation pipeline...
2025-04-16 17:24:51,567 - root - INFO - Loaded checkpoint sucessfully
2025-04-16 17:24:52,019 - embedding_process - INFO - Running detection and segmentation pipeline...
2025-04-16 17:24:54,552 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-04-16 17:24:54,653 - root - INFO - Computing image embeddings for the provided image...
2025-04-16 17:24:54,929 - root - INFO - Image embeddings computed.
2025-04-16 17:24:55,505 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-04-16 17:24:55,537 - root - INFO - Computing image embeddings for the provided image...
2025-04-16 17:24:55,626 - root - INFO - Image embeddings computed.
2025-04-16 17:24:58,891 - embedding_process - INFO - Pipeline completed in 6.87 seconds
2025-04-16 17:24:58,892 - embedding_process - INFO - Initializing embedding generator with models: ['clip', 'vit', 'resnet50']
2025-04-16 17:25:01,533 - embedding_process - INFO - === Embedding Model Details ===
2025-04-16 17:25:01,534 - embedding_process - INFO - Model: ModelType.CLIP
2025-04-16 17:25:01,534 - embedding_process - INFO -   Module text_model.embeddings.token_embedding is on device cuda:0
2025-04-16 17:25:01,534 - embedding_process - INFO -   Module text_model.embeddings.position_embedding is on device cuda:0
2025-04-16 17:25:01,534 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,534 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,534 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,534 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,535 - embedding_process - INFO -   Module text_model.encoder.layers.0.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,535 - embedding_process - INFO -   Module text_model.encoder.layers.0.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,535 - embedding_process - INFO -   Module text_model.encoder.layers.0.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,535 - embedding_process - INFO -   Module text_model.encoder.layers.0.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,535 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,535 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,535 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,535 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,535 - embedding_process - INFO -   Module text_model.encoder.layers.1.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,536 - embedding_process - INFO -   Module text_model.encoder.layers.1.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,536 - embedding_process - INFO -   Module text_model.encoder.layers.1.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,536 - embedding_process - INFO -   Module text_model.encoder.layers.1.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,536 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,536 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,536 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,536 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,536 - embedding_process - INFO -   Module text_model.encoder.layers.2.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,537 - embedding_process - INFO -   Module text_model.encoder.layers.2.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,537 - embedding_process - INFO -   Module text_model.encoder.layers.2.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,537 - embedding_process - INFO -   Module text_model.encoder.layers.2.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,537 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,537 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,537 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,537 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,537 - embedding_process - INFO -   Module text_model.encoder.layers.3.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,537 - embedding_process - INFO -   Module text_model.encoder.layers.3.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,538 - embedding_process - INFO -   Module text_model.encoder.layers.3.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,538 - embedding_process - INFO -   Module text_model.encoder.layers.3.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,538 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,538 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,538 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,538 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,538 - embedding_process - INFO -   Module text_model.encoder.layers.4.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,538 - embedding_process - INFO -   Module text_model.encoder.layers.4.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,538 - embedding_process - INFO -   Module text_model.encoder.layers.4.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.4.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.5.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.5.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.5.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.5.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,539 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,540 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,540 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,540 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,540 - embedding_process - INFO -   Module text_model.encoder.layers.6.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,540 - embedding_process - INFO -   Module text_model.encoder.layers.6.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,540 - embedding_process - INFO -   Module text_model.encoder.layers.6.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,540 - embedding_process - INFO -   Module text_model.encoder.layers.6.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,540 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,541 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,541 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,541 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,541 - embedding_process - INFO -   Module text_model.encoder.layers.7.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,541 - embedding_process - INFO -   Module text_model.encoder.layers.7.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,541 - embedding_process - INFO -   Module text_model.encoder.layers.7.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,541 - embedding_process - INFO -   Module text_model.encoder.layers.7.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,541 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,541 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,542 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,542 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,542 - embedding_process - INFO -   Module text_model.encoder.layers.8.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,542 - embedding_process - INFO -   Module text_model.encoder.layers.8.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,542 - embedding_process - INFO -   Module text_model.encoder.layers.8.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,542 - embedding_process - INFO -   Module text_model.encoder.layers.8.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,542 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,542 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,542 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,543 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,543 - embedding_process - INFO -   Module text_model.encoder.layers.9.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,543 - embedding_process - INFO -   Module text_model.encoder.layers.9.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,543 - embedding_process - INFO -   Module text_model.encoder.layers.9.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,543 - embedding_process - INFO -   Module text_model.encoder.layers.9.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,543 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,543 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,543 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,543 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.10.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.10.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.10.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.10.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.11.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,544 - embedding_process - INFO -   Module text_model.encoder.layers.11.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,545 - embedding_process - INFO -   Module text_model.encoder.layers.11.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,545 - embedding_process - INFO -   Module text_model.encoder.layers.11.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,545 - embedding_process - INFO -   Module text_model.final_layer_norm is on device cuda:0
2025-04-16 17:25:01,545 - embedding_process - INFO -   Module vision_model.embeddings.patch_embedding is on device cuda:0
2025-04-16 17:25:01,545 - embedding_process - INFO -   Module vision_model.embeddings.position_embedding is on device cuda:0
2025-04-16 17:25:01,545 - embedding_process - INFO -   Module vision_model.pre_layrnorm is on device cuda:0
2025-04-16 17:25:01,545 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,545 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,546 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,546 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,546 - embedding_process - INFO -   Module vision_model.encoder.layers.0.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,546 - embedding_process - INFO -   Module vision_model.encoder.layers.0.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,546 - embedding_process - INFO -   Module vision_model.encoder.layers.0.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,546 - embedding_process - INFO -   Module vision_model.encoder.layers.0.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,546 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,546 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,546 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,547 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,547 - embedding_process - INFO -   Module vision_model.encoder.layers.1.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,547 - embedding_process - INFO -   Module vision_model.encoder.layers.1.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,547 - embedding_process - INFO -   Module vision_model.encoder.layers.1.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,547 - embedding_process - INFO -   Module vision_model.encoder.layers.1.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,547 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,547 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,547 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,547 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,548 - embedding_process - INFO -   Module vision_model.encoder.layers.2.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,548 - embedding_process - INFO -   Module vision_model.encoder.layers.2.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,548 - embedding_process - INFO -   Module vision_model.encoder.layers.2.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,548 - embedding_process - INFO -   Module vision_model.encoder.layers.2.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,548 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,548 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,548 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,548 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,548 - embedding_process - INFO -   Module vision_model.encoder.layers.3.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,549 - embedding_process - INFO -   Module vision_model.encoder.layers.3.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,549 - embedding_process - INFO -   Module vision_model.encoder.layers.3.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,549 - embedding_process - INFO -   Module vision_model.encoder.layers.3.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,549 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,549 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,549 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,549 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,549 - embedding_process - INFO -   Module vision_model.encoder.layers.4.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,549 - embedding_process - INFO -   Module vision_model.encoder.layers.4.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,550 - embedding_process - INFO -   Module vision_model.encoder.layers.4.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,550 - embedding_process - INFO -   Module vision_model.encoder.layers.4.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,550 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,550 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,550 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,550 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,550 - embedding_process - INFO -   Module vision_model.encoder.layers.5.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,550 - embedding_process - INFO -   Module vision_model.encoder.layers.5.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,550 - embedding_process - INFO -   Module vision_model.encoder.layers.5.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,551 - embedding_process - INFO -   Module vision_model.encoder.layers.5.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,551 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,551 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,551 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,551 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,551 - embedding_process - INFO -   Module vision_model.encoder.layers.6.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,551 - embedding_process - INFO -   Module vision_model.encoder.layers.6.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,551 - embedding_process - INFO -   Module vision_model.encoder.layers.6.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,551 - embedding_process - INFO -   Module vision_model.encoder.layers.6.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,552 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,552 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,552 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,552 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,552 - embedding_process - INFO -   Module vision_model.encoder.layers.7.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,552 - embedding_process - INFO -   Module vision_model.encoder.layers.7.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,552 - embedding_process - INFO -   Module vision_model.encoder.layers.7.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,552 - embedding_process - INFO -   Module vision_model.encoder.layers.7.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,552 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,553 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,553 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,553 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,553 - embedding_process - INFO -   Module vision_model.encoder.layers.8.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,553 - embedding_process - INFO -   Module vision_model.encoder.layers.8.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,553 - embedding_process - INFO -   Module vision_model.encoder.layers.8.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,553 - embedding_process - INFO -   Module vision_model.encoder.layers.8.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,553 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,553 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,554 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,554 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,554 - embedding_process - INFO -   Module vision_model.encoder.layers.9.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,554 - embedding_process - INFO -   Module vision_model.encoder.layers.9.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,554 - embedding_process - INFO -   Module vision_model.encoder.layers.9.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,554 - embedding_process - INFO -   Module vision_model.encoder.layers.9.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,554 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,555 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,555 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,555 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,555 - embedding_process - INFO -   Module vision_model.encoder.layers.10.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,555 - embedding_process - INFO -   Module vision_model.encoder.layers.10.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,555 - embedding_process - INFO -   Module vision_model.encoder.layers.10.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,555 - embedding_process - INFO -   Module vision_model.encoder.layers.10.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,556 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:01,556 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:01,556 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:01,556 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:01,556 - embedding_process - INFO -   Module vision_model.encoder.layers.11.layer_norm1 is on device cuda:0
2025-04-16 17:25:01,556 - embedding_process - INFO -   Module vision_model.encoder.layers.11.mlp.fc1 is on device cuda:0
2025-04-16 17:25:01,556 - embedding_process - INFO -   Module vision_model.encoder.layers.11.mlp.fc2 is on device cuda:0
2025-04-16 17:25:01,557 - embedding_process - INFO -   Module vision_model.encoder.layers.11.layer_norm2 is on device cuda:0
2025-04-16 17:25:01,557 - embedding_process - INFO -   Module vision_model.post_layernorm is on device cuda:0
2025-04-16 17:25:01,557 - embedding_process - INFO -   Module visual_projection is on device cuda:0
2025-04-16 17:25:01,557 - embedding_process - INFO -   Module text_projection is on device cuda:0
2025-04-16 17:25:01,557 - embedding_process - INFO - Model: ModelType.VIT
2025-04-16 17:25:01,557 - embedding_process - INFO -   Module embeddings.patch_embeddings.projection is on device cuda:0
2025-04-16 17:25:01,557 - embedding_process - INFO -   Module encoder.layer.0.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,558 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,558 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,558 - embedding_process - INFO -   Module encoder.layer.0.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,558 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,558 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,558 - embedding_process - INFO -   Module encoder.layer.0.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,558 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,559 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,559 - embedding_process - INFO -   Module encoder.layer.0.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,559 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,559 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,559 - embedding_process - INFO -   Module encoder.layer.0.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,559 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,559 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,560 - embedding_process - INFO -   Module encoder.layer.0.output.dense is on device cuda:0
2025-04-16 17:25:01,560 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,560 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,560 - embedding_process - INFO -   Module encoder.layer.0.layernorm_before is on device cuda:0
2025-04-16 17:25:01,560 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,560 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,560 - embedding_process - INFO -   Module encoder.layer.0.layernorm_after is on device cuda:0
2025-04-16 17:25:01,561 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,561 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,561 - embedding_process - INFO -   Module encoder.layer.1.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,561 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,561 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,561 - embedding_process - INFO -   Module encoder.layer.1.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,561 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,561 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,562 - embedding_process - INFO -   Module encoder.layer.1.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,562 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,562 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,562 - embedding_process - INFO -   Module encoder.layer.1.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,562 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,562 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,562 - embedding_process - INFO -   Module encoder.layer.1.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,563 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,563 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,563 - embedding_process - INFO -   Module encoder.layer.1.output.dense is on device cuda:0
2025-04-16 17:25:01,563 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,563 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,563 - embedding_process - INFO -   Module encoder.layer.1.layernorm_before is on device cuda:0
2025-04-16 17:25:01,563 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,563 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,564 - embedding_process - INFO -   Module encoder.layer.1.layernorm_after is on device cuda:0
2025-04-16 17:25:01,564 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,564 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,564 - embedding_process - INFO -   Module encoder.layer.2.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,564 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,564 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,565 - embedding_process - INFO -   Module encoder.layer.2.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,565 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,565 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,565 - embedding_process - INFO -   Module encoder.layer.2.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,565 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,565 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,565 - embedding_process - INFO -   Module encoder.layer.2.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,565 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,566 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,566 - embedding_process - INFO -   Module encoder.layer.2.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,566 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,566 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,566 - embedding_process - INFO -   Module encoder.layer.2.output.dense is on device cuda:0
2025-04-16 17:25:01,566 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,566 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,567 - embedding_process - INFO -   Module encoder.layer.2.layernorm_before is on device cuda:0
2025-04-16 17:25:01,567 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,567 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,567 - embedding_process - INFO -   Module encoder.layer.2.layernorm_after is on device cuda:0
2025-04-16 17:25:01,567 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,567 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,567 - embedding_process - INFO -   Module encoder.layer.3.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,567 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,568 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,568 - embedding_process - INFO -   Module encoder.layer.3.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,568 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,568 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,568 - embedding_process - INFO -   Module encoder.layer.3.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,568 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,568 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,568 - embedding_process - INFO -   Module encoder.layer.3.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,569 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,569 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,569 - embedding_process - INFO -   Module encoder.layer.3.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,569 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,569 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,569 - embedding_process - INFO -   Module encoder.layer.3.output.dense is on device cuda:0
2025-04-16 17:25:01,569 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,570 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,570 - embedding_process - INFO -   Module encoder.layer.3.layernorm_before is on device cuda:0
2025-04-16 17:25:01,570 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,570 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,570 - embedding_process - INFO -   Module encoder.layer.3.layernorm_after is on device cuda:0
2025-04-16 17:25:01,570 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,570 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,570 - embedding_process - INFO -   Module encoder.layer.4.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,571 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,571 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,571 - embedding_process - INFO -   Module encoder.layer.4.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,571 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,571 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,571 - embedding_process - INFO -   Module encoder.layer.4.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,571 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,571 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,572 - embedding_process - INFO -   Module encoder.layer.4.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,572 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,572 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,572 - embedding_process - INFO -   Module encoder.layer.4.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,572 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,572 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,572 - embedding_process - INFO -   Module encoder.layer.4.output.dense is on device cuda:0
2025-04-16 17:25:01,573 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,573 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,573 - embedding_process - INFO -   Module encoder.layer.4.layernorm_before is on device cuda:0
2025-04-16 17:25:01,573 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,573 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,573 - embedding_process - INFO -   Module encoder.layer.4.layernorm_after is on device cuda:0
2025-04-16 17:25:01,573 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,573 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,574 - embedding_process - INFO -   Module encoder.layer.5.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,574 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,574 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,574 - embedding_process - INFO -   Module encoder.layer.5.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,574 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,574 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,575 - embedding_process - INFO -   Module encoder.layer.5.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,575 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,575 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,575 - embedding_process - INFO -   Module encoder.layer.5.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,575 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,575 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,575 - embedding_process - INFO -   Module encoder.layer.5.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,575 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,575 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,575 - embedding_process - INFO -   Module encoder.layer.5.output.dense is on device cuda:0
2025-04-16 17:25:01,575 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,576 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,576 - embedding_process - INFO -   Module encoder.layer.5.layernorm_before is on device cuda:0
2025-04-16 17:25:01,576 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,576 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,576 - embedding_process - INFO -   Module encoder.layer.5.layernorm_after is on device cuda:0
2025-04-16 17:25:01,576 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,576 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,576 - embedding_process - INFO -   Module encoder.layer.6.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,576 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,576 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,576 - embedding_process - INFO -   Module encoder.layer.6.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,577 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,577 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,577 - embedding_process - INFO -   Module encoder.layer.6.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,577 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,577 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,577 - embedding_process - INFO -   Module encoder.layer.6.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,577 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,577 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,577 - embedding_process - INFO -   Module encoder.layer.6.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,577 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,577 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,578 - embedding_process - INFO -   Module encoder.layer.6.output.dense is on device cuda:0
2025-04-16 17:25:01,578 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,578 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,578 - embedding_process - INFO -   Module encoder.layer.6.layernorm_before is on device cuda:0
2025-04-16 17:25:01,578 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,578 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,578 - embedding_process - INFO -   Module encoder.layer.6.layernorm_after is on device cuda:0
2025-04-16 17:25:01,578 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,578 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,578 - embedding_process - INFO -   Module encoder.layer.7.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,578 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,578 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,579 - embedding_process - INFO -   Module encoder.layer.7.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,579 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,579 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,579 - embedding_process - INFO -   Module encoder.layer.7.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,579 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,579 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,579 - embedding_process - INFO -   Module encoder.layer.7.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,579 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,579 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,579 - embedding_process - INFO -   Module encoder.layer.7.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,579 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,579 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,580 - embedding_process - INFO -   Module encoder.layer.7.output.dense is on device cuda:0
2025-04-16 17:25:01,580 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,580 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,580 - embedding_process - INFO -   Module encoder.layer.7.layernorm_before is on device cuda:0
2025-04-16 17:25:01,580 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,580 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,580 - embedding_process - INFO -   Module encoder.layer.7.layernorm_after is on device cuda:0
2025-04-16 17:25:01,580 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,580 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,580 - embedding_process - INFO -   Module encoder.layer.8.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,581 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,581 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,581 - embedding_process - INFO -   Module encoder.layer.8.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,581 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,581 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,581 - embedding_process - INFO -   Module encoder.layer.8.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,581 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,581 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,581 - embedding_process - INFO -   Module encoder.layer.8.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,581 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,581 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,581 - embedding_process - INFO -   Module encoder.layer.8.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,582 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,582 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,582 - embedding_process - INFO -   Module encoder.layer.8.output.dense is on device cuda:0
2025-04-16 17:25:01,582 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,582 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,582 - embedding_process - INFO -   Module encoder.layer.8.layernorm_before is on device cuda:0
2025-04-16 17:25:01,582 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,582 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,582 - embedding_process - INFO -   Module encoder.layer.8.layernorm_after is on device cuda:0
2025-04-16 17:25:01,582 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,582 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,582 - embedding_process - INFO -   Module encoder.layer.9.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,583 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,583 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,583 - embedding_process - INFO -   Module encoder.layer.9.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,583 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,583 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,583 - embedding_process - INFO -   Module encoder.layer.9.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,583 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,583 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,583 - embedding_process - INFO -   Module encoder.layer.9.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,583 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,583 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,583 - embedding_process - INFO -   Module encoder.layer.9.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,584 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,584 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,584 - embedding_process - INFO -   Module encoder.layer.9.output.dense is on device cuda:0
2025-04-16 17:25:01,584 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,584 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,584 - embedding_process - INFO -   Module encoder.layer.9.layernorm_before is on device cuda:0
2025-04-16 17:25:01,584 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,584 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,584 - embedding_process - INFO -   Module encoder.layer.9.layernorm_after is on device cuda:0
2025-04-16 17:25:01,584 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,584 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,584 - embedding_process - INFO -   Module encoder.layer.10.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,585 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,585 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,585 - embedding_process - INFO -   Module encoder.layer.10.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,585 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,585 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,585 - embedding_process - INFO -   Module encoder.layer.10.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,585 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,585 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,585 - embedding_process - INFO -   Module encoder.layer.10.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,585 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,585 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,586 - embedding_process - INFO -   Module encoder.layer.10.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,586 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,586 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,586 - embedding_process - INFO -   Module encoder.layer.10.output.dense is on device cuda:0
2025-04-16 17:25:01,586 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,586 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,586 - embedding_process - INFO -   Module encoder.layer.10.layernorm_before is on device cuda:0
2025-04-16 17:25:01,586 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,586 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,587 - embedding_process - INFO -   Module encoder.layer.10.layernorm_after is on device cuda:0
2025-04-16 17:25:01,587 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,587 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,587 - embedding_process - INFO -   Module encoder.layer.11.attention.attention.query is on device cuda:0
2025-04-16 17:25:01,587 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,587 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,587 - embedding_process - INFO -   Module encoder.layer.11.attention.attention.key is on device cuda:0
2025-04-16 17:25:01,587 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,587 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,587 - embedding_process - INFO -   Module encoder.layer.11.attention.attention.value is on device cuda:0
2025-04-16 17:25:01,588 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,588 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,588 - embedding_process - INFO -   Module encoder.layer.11.attention.output.dense is on device cuda:0
2025-04-16 17:25:01,588 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:01,588 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,588 - embedding_process - INFO -   Module encoder.layer.11.intermediate.dense is on device cuda:0
2025-04-16 17:25:01,588 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:01,588 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:01,588 - embedding_process - INFO -   Module encoder.layer.11.output.dense is on device cuda:0
2025-04-16 17:25:01,589 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:01,589 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,589 - embedding_process - INFO -   Module encoder.layer.11.layernorm_before is on device cuda:0
2025-04-16 17:25:01,589 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,589 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,589 - embedding_process - INFO -   Module encoder.layer.11.layernorm_after is on device cuda:0
2025-04-16 17:25:01,589 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,589 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:01,589 - embedding_process - INFO -   Module layernorm is on device cuda:0
2025-04-16 17:25:01,589 - embedding_process - INFO -   Module pooler.dense is on device cuda:0
2025-04-16 17:25:01,590 - embedding_process - INFO - Model: ModelType.RESNET50
2025-04-16 17:25:01,590 - embedding_process - INFO -   Module 0 is on device cuda:0
2025-04-16 17:25:01,590 - embedding_process - INFO -   Weight - Shape: torch.Size([64, 3, 7, 7]), Type: torch.float32
2025-04-16 17:25:01,590 - embedding_process - INFO -   Module 1 is on device cuda:0
2025-04-16 17:25:01,590 - embedding_process - INFO -   Weight - Shape: torch.Size([64]), Type: torch.float32
2025-04-16 17:25:01,590 - embedding_process - INFO -   Bias - Shape: torch.Size([64]), Type: torch.float32
2025-04-16 17:25:01,590 - embedding_process - INFO -   Module 4.0.conv1 is on device cuda:0
2025-04-16 17:25:01,590 - embedding_process - INFO -   Module 4.0.bn1 is on device cuda:0
2025-04-16 17:25:01,590 - embedding_process - INFO -   Module 4.0.conv2 is on device cuda:0
2025-04-16 17:25:01,591 - embedding_process - INFO -   Module 4.0.bn2 is on device cuda:0
2025-04-16 17:25:01,591 - embedding_process - INFO -   Module 4.0.conv3 is on device cuda:0
2025-04-16 17:25:01,591 - embedding_process - INFO -   Module 4.0.bn3 is on device cuda:0
2025-04-16 17:25:01,591 - embedding_process - INFO -   Module 4.0.downsample.0 is on device cuda:0
2025-04-16 17:25:01,591 - embedding_process - INFO -   Module 4.0.downsample.1 is on device cuda:0
2025-04-16 17:25:01,591 - embedding_process - INFO -   Module 4.1.conv1 is on device cuda:0
2025-04-16 17:25:01,591 - embedding_process - INFO -   Module 4.1.bn1 is on device cuda:0
2025-04-16 17:25:01,591 - embedding_process - INFO -   Module 4.1.conv2 is on device cuda:0
2025-04-16 17:25:01,591 - embedding_process - INFO -   Module 4.1.bn2 is on device cuda:0
2025-04-16 17:25:01,592 - embedding_process - INFO -   Module 4.1.conv3 is on device cuda:0
2025-04-16 17:25:01,592 - embedding_process - INFO -   Module 4.1.bn3 is on device cuda:0
2025-04-16 17:25:01,592 - embedding_process - INFO -   Module 4.2.conv1 is on device cuda:0
2025-04-16 17:25:01,592 - embedding_process - INFO -   Module 4.2.bn1 is on device cuda:0
2025-04-16 17:25:01,592 - embedding_process - INFO -   Module 4.2.conv2 is on device cuda:0
2025-04-16 17:25:01,592 - embedding_process - INFO -   Module 4.2.bn2 is on device cuda:0
2025-04-16 17:25:01,592 - embedding_process - INFO -   Module 4.2.conv3 is on device cuda:0
2025-04-16 17:25:01,592 - embedding_process - INFO -   Module 4.2.bn3 is on device cuda:0
2025-04-16 17:25:01,592 - embedding_process - INFO -   Module 5.0.conv1 is on device cuda:0
2025-04-16 17:25:01,593 - embedding_process - INFO -   Module 5.0.bn1 is on device cuda:0
2025-04-16 17:25:01,593 - embedding_process - INFO -   Module 5.0.conv2 is on device cuda:0
2025-04-16 17:25:01,593 - embedding_process - INFO -   Module 5.0.bn2 is on device cuda:0
2025-04-16 17:25:01,593 - embedding_process - INFO -   Module 5.0.conv3 is on device cuda:0
2025-04-16 17:25:01,593 - embedding_process - INFO -   Module 5.0.bn3 is on device cuda:0
2025-04-16 17:25:01,593 - embedding_process - INFO -   Module 5.0.downsample.0 is on device cuda:0
2025-04-16 17:25:01,593 - embedding_process - INFO -   Module 5.0.downsample.1 is on device cuda:0
2025-04-16 17:25:01,593 - embedding_process - INFO -   Module 5.1.conv1 is on device cuda:0
2025-04-16 17:25:01,593 - embedding_process - INFO -   Module 5.1.bn1 is on device cuda:0
2025-04-16 17:25:01,594 - embedding_process - INFO -   Module 5.1.conv2 is on device cuda:0
2025-04-16 17:25:01,594 - embedding_process - INFO -   Module 5.1.bn2 is on device cuda:0
2025-04-16 17:25:01,594 - embedding_process - INFO -   Module 5.1.conv3 is on device cuda:0
2025-04-16 17:25:01,594 - embedding_process - INFO -   Module 5.1.bn3 is on device cuda:0
2025-04-16 17:25:01,594 - embedding_process - INFO -   Module 5.2.conv1 is on device cuda:0
2025-04-16 17:25:01,594 - embedding_process - INFO -   Module 5.2.bn1 is on device cuda:0
2025-04-16 17:25:01,594 - embedding_process - INFO -   Module 5.2.conv2 is on device cuda:0
2025-04-16 17:25:01,594 - embedding_process - INFO -   Module 5.2.bn2 is on device cuda:0
2025-04-16 17:25:01,594 - embedding_process - INFO -   Module 5.2.conv3 is on device cuda:0
2025-04-16 17:25:01,595 - embedding_process - INFO -   Module 5.2.bn3 is on device cuda:0
2025-04-16 17:25:01,595 - embedding_process - INFO -   Module 5.3.conv1 is on device cuda:0
2025-04-16 17:25:01,595 - embedding_process - INFO -   Module 5.3.bn1 is on device cuda:0
2025-04-16 17:25:01,595 - embedding_process - INFO -   Module 5.3.conv2 is on device cuda:0
2025-04-16 17:25:01,595 - embedding_process - INFO -   Module 5.3.bn2 is on device cuda:0
2025-04-16 17:25:01,595 - embedding_process - INFO -   Module 5.3.conv3 is on device cuda:0
2025-04-16 17:25:01,595 - embedding_process - INFO -   Module 5.3.bn3 is on device cuda:0
2025-04-16 17:25:01,595 - embedding_process - INFO -   Module 6.0.conv1 is on device cuda:0
2025-04-16 17:25:01,595 - embedding_process - INFO -   Module 6.0.bn1 is on device cuda:0
2025-04-16 17:25:01,596 - embedding_process - INFO -   Module 6.0.conv2 is on device cuda:0
2025-04-16 17:25:01,596 - embedding_process - INFO -   Module 6.0.bn2 is on device cuda:0
2025-04-16 17:25:01,596 - embedding_process - INFO -   Module 6.0.conv3 is on device cuda:0
2025-04-16 17:25:01,596 - embedding_process - INFO -   Module 6.0.bn3 is on device cuda:0
2025-04-16 17:25:01,596 - embedding_process - INFO -   Module 6.0.downsample.0 is on device cuda:0
2025-04-16 17:25:01,596 - embedding_process - INFO -   Module 6.0.downsample.1 is on device cuda:0
2025-04-16 17:25:01,596 - embedding_process - INFO -   Module 6.1.conv1 is on device cuda:0
2025-04-16 17:25:01,596 - embedding_process - INFO -   Module 6.1.bn1 is on device cuda:0
2025-04-16 17:25:01,596 - embedding_process - INFO -   Module 6.1.conv2 is on device cuda:0
2025-04-16 17:25:01,597 - embedding_process - INFO -   Module 6.1.bn2 is on device cuda:0
2025-04-16 17:25:01,597 - embedding_process - INFO -   Module 6.1.conv3 is on device cuda:0
2025-04-16 17:25:01,597 - embedding_process - INFO -   Module 6.1.bn3 is on device cuda:0
2025-04-16 17:25:01,597 - embedding_process - INFO -   Module 6.2.conv1 is on device cuda:0
2025-04-16 17:25:01,597 - embedding_process - INFO -   Module 6.2.bn1 is on device cuda:0
2025-04-16 17:25:01,597 - embedding_process - INFO -   Module 6.2.conv2 is on device cuda:0
2025-04-16 17:25:01,597 - embedding_process - INFO -   Module 6.2.bn2 is on device cuda:0
2025-04-16 17:25:01,597 - embedding_process - INFO -   Module 6.2.conv3 is on device cuda:0
2025-04-16 17:25:01,597 - embedding_process - INFO -   Module 6.2.bn3 is on device cuda:0
2025-04-16 17:25:01,598 - embedding_process - INFO -   Module 6.3.conv1 is on device cuda:0
2025-04-16 17:25:01,598 - embedding_process - INFO -   Module 6.3.bn1 is on device cuda:0
2025-04-16 17:25:01,598 - embedding_process - INFO -   Module 6.3.conv2 is on device cuda:0
2025-04-16 17:25:01,598 - embedding_process - INFO -   Module 6.3.bn2 is on device cuda:0
2025-04-16 17:25:01,598 - embedding_process - INFO -   Module 6.3.conv3 is on device cuda:0
2025-04-16 17:25:01,598 - embedding_process - INFO -   Module 6.3.bn3 is on device cuda:0
2025-04-16 17:25:01,598 - embedding_process - INFO -   Module 6.4.conv1 is on device cuda:0
2025-04-16 17:25:01,598 - embedding_process - INFO -   Module 6.4.bn1 is on device cuda:0
2025-04-16 17:25:01,599 - embedding_process - INFO -   Module 6.4.conv2 is on device cuda:0
2025-04-16 17:25:01,599 - embedding_process - INFO -   Module 6.4.bn2 is on device cuda:0
2025-04-16 17:25:01,599 - embedding_process - INFO -   Module 6.4.conv3 is on device cuda:0
2025-04-16 17:25:01,599 - embedding_process - INFO -   Module 6.4.bn3 is on device cuda:0
2025-04-16 17:25:01,599 - embedding_process - INFO -   Module 6.5.conv1 is on device cuda:0
2025-04-16 17:25:01,599 - embedding_process - INFO -   Module 6.5.bn1 is on device cuda:0
2025-04-16 17:25:01,599 - embedding_process - INFO -   Module 6.5.conv2 is on device cuda:0
2025-04-16 17:25:01,599 - embedding_process - INFO -   Module 6.5.bn2 is on device cuda:0
2025-04-16 17:25:01,600 - embedding_process - INFO -   Module 6.5.conv3 is on device cuda:0
2025-04-16 17:25:01,600 - embedding_process - INFO -   Module 6.5.bn3 is on device cuda:0
2025-04-16 17:25:01,600 - embedding_process - INFO -   Module 7.0.conv1 is on device cuda:0
2025-04-16 17:25:01,600 - embedding_process - INFO -   Module 7.0.bn1 is on device cuda:0
2025-04-16 17:25:01,600 - embedding_process - INFO -   Module 7.0.conv2 is on device cuda:0
2025-04-16 17:25:01,600 - embedding_process - INFO -   Module 7.0.bn2 is on device cuda:0
2025-04-16 17:25:01,600 - embedding_process - INFO -   Module 7.0.conv3 is on device cuda:0
2025-04-16 17:25:01,601 - embedding_process - INFO -   Module 7.0.bn3 is on device cuda:0
2025-04-16 17:25:01,601 - embedding_process - INFO -   Module 7.0.downsample.0 is on device cuda:0
2025-04-16 17:25:01,601 - embedding_process - INFO -   Module 7.0.downsample.1 is on device cuda:0
2025-04-16 17:25:01,601 - embedding_process - INFO -   Module 7.1.conv1 is on device cuda:0
2025-04-16 17:25:01,601 - embedding_process - INFO -   Module 7.1.bn1 is on device cuda:0
2025-04-16 17:25:01,601 - embedding_process - INFO -   Module 7.1.conv2 is on device cuda:0
2025-04-16 17:25:01,601 - embedding_process - INFO -   Module 7.1.bn2 is on device cuda:0
2025-04-16 17:25:01,601 - embedding_process - INFO -   Module 7.1.conv3 is on device cuda:0
2025-04-16 17:25:01,602 - embedding_process - INFO -   Module 7.1.bn3 is on device cuda:0
2025-04-16 17:25:01,602 - embedding_process - INFO -   Module 7.2.conv1 is on device cuda:0
2025-04-16 17:25:01,602 - embedding_process - INFO -   Module 7.2.bn1 is on device cuda:0
2025-04-16 17:25:01,602 - embedding_process - INFO -   Module 7.2.conv2 is on device cuda:0
2025-04-16 17:25:01,602 - embedding_process - INFO -   Module 7.2.bn2 is on device cuda:0
2025-04-16 17:25:01,602 - embedding_process - INFO -   Module 7.2.conv3 is on device cuda:0
2025-04-16 17:25:01,602 - embedding_process - INFO -   Module 7.2.bn3 is on device cuda:0
2025-04-16 17:25:01,602 - embedding_process - INFO - Loading original image: data/tesseract.png
2025-04-16 17:25:01,615 - embedding_process - INFO - Original image shape: (453, 908, 3), dtype: uint8
2025-04-16 17:25:01,615 - embedding_process - INFO - Found 36 detections in the image
2025-04-16 17:25:01,615 - embedding_process - INFO - Generating embeddings for detections...
2025-04-16 17:25:01,615 - embedding_process - INFO - 
Processing detection 1/36: tesseract_0_00_0.00
2025-04-16 17:25:01,635 - embedding_process - INFO - Generating embeddings for detection tesseract_0_00_0.00...
2025-04-16 17:25:01,635 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:01,670 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:01,671 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:01,671 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:01,705 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:01,705 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:01,738 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:01,739 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:01,740 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_00_0.00_embeddings.json
2025-04-16 17:25:01,741 - embedding_process - INFO - 
Processing detection 2/36: tesseract_0_01_0.00
2025-04-16 17:25:01,747 - embedding_process - INFO - Generating embeddings for detection tesseract_0_01_0.00...
2025-04-16 17:25:01,747 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:01,771 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:01,772 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:01,772 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:01,797 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:01,797 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:01,814 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:01,815 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:01,816 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_01_0.00_embeddings.json
2025-04-16 17:25:01,817 - embedding_process - INFO - 
Processing detection 3/36: tesseract_0_02_0.00
2025-04-16 17:25:01,819 - embedding_process - INFO - Generating embeddings for detection tesseract_0_02_0.00...
2025-04-16 17:25:01,820 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:01,841 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:01,842 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:01,842 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:01,864 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:01,864 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:01,880 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:01,881 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:01,882 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_02_0.00_embeddings.json
2025-04-16 17:25:01,882 - embedding_process - INFO - 
Processing detection 4/36: tesseract_0_03_0.00
2025-04-16 17:25:01,888 - embedding_process - INFO - Generating embeddings for detection tesseract_0_03_0.00...
2025-04-16 17:25:01,888 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:01,911 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:01,912 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:01,912 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:01,935 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:01,935 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:01,952 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:01,953 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:01,954 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_03_0.00_embeddings.json
2025-04-16 17:25:01,955 - embedding_process - INFO - 
Processing detection 5/36: tesseract_0_04_0.00
2025-04-16 17:25:01,957 - embedding_process - INFO - Generating embeddings for detection tesseract_0_04_0.00...
2025-04-16 17:25:01,957 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:01,978 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:01,979 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:01,980 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,000 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,000 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,017 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,018 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,020 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_04_0.00_embeddings.json
2025-04-16 17:25:02,021 - embedding_process - INFO - 
Processing detection 6/36: tesseract_0_05_0.00
2025-04-16 17:25:02,022 - embedding_process - INFO - Generating embeddings for detection tesseract_0_05_0.00...
2025-04-16 17:25:02,022 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,042 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,042 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,043 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,062 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,062 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,076 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,076 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,078 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_05_0.00_embeddings.json
2025-04-16 17:25:02,078 - embedding_process - INFO - 
Processing detection 7/36: tesseract_0_06_0.00
2025-04-16 17:25:02,079 - embedding_process - INFO - Generating embeddings for detection tesseract_0_06_0.00...
2025-04-16 17:25:02,079 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,097 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,098 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,098 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,117 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,117 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,131 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,132 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,133 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_06_0.00_embeddings.json
2025-04-16 17:25:02,133 - embedding_process - INFO - 
Processing detection 8/36: tesseract_0_07_0.00
2025-04-16 17:25:02,134 - embedding_process - INFO - Generating embeddings for detection tesseract_0_07_0.00...
2025-04-16 17:25:02,134 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,153 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,154 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,154 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,173 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,173 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,188 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,189 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,190 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_07_0.00_embeddings.json
2025-04-16 17:25:02,190 - embedding_process - INFO - 
Processing detection 9/36: tesseract_0_08_0.00
2025-04-16 17:25:02,195 - embedding_process - INFO - Generating embeddings for detection tesseract_0_08_0.00...
2025-04-16 17:25:02,195 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,216 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,217 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,217 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,238 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,239 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,255 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,255 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,257 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_08_0.00_embeddings.json
2025-04-16 17:25:02,257 - embedding_process - INFO - 
Processing detection 10/36: tesseract_0_09_0.00
2025-04-16 17:25:02,265 - embedding_process - INFO - Generating embeddings for detection tesseract_0_09_0.00...
2025-04-16 17:25:02,265 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,288 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,288 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,289 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,311 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,311 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,329 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,330 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,331 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_09_0.00_embeddings.json
2025-04-16 17:25:02,331 - embedding_process - INFO - 
Processing detection 11/36: tesseract_0_10_0.00
2025-04-16 17:25:02,332 - embedding_process - INFO - Generating embeddings for detection tesseract_0_10_0.00...
2025-04-16 17:25:02,332 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,351 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,352 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,352 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,371 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,371 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,385 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,386 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,388 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_10_0.00_embeddings.json
2025-04-16 17:25:02,388 - embedding_process - INFO - 
Processing detection 12/36: tesseract_0_11_0.00
2025-04-16 17:25:02,389 - embedding_process - INFO - Generating embeddings for detection tesseract_0_11_0.00...
2025-04-16 17:25:02,389 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,408 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,409 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,409 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,430 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,430 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,444 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,445 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,447 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_11_0.00_embeddings.json
2025-04-16 17:25:02,447 - embedding_process - INFO - 
Processing detection 13/36: tesseract_0_12_0.00
2025-04-16 17:25:02,448 - embedding_process - INFO - Generating embeddings for detection tesseract_0_12_0.00...
2025-04-16 17:25:02,449 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,470 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,471 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,471 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,492 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,492 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,508 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,509 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,510 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_12_0.00_embeddings.json
2025-04-16 17:25:02,511 - embedding_process - INFO - 
Processing detection 14/36: tesseract_0_13_0.00
2025-04-16 17:25:02,513 - embedding_process - INFO - Generating embeddings for detection tesseract_0_13_0.00...
2025-04-16 17:25:02,513 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,533 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,534 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,534 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,555 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,555 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,571 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,572 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,573 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_13_0.00_embeddings.json
2025-04-16 17:25:02,573 - embedding_process - INFO - 
Processing detection 15/36: tesseract_0_14_0.00
2025-04-16 17:25:02,581 - embedding_process - INFO - Generating embeddings for detection tesseract_0_14_0.00...
2025-04-16 17:25:02,581 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,606 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,606 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,607 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,630 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,630 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,649 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,650 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,652 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_14_0.00_embeddings.json
2025-04-16 17:25:02,652 - embedding_process - INFO - 
Processing detection 16/36: tesseract_0_15_0.00
2025-04-16 17:25:02,652 - embedding_process - INFO - Generating embeddings for detection tesseract_0_15_0.00...
2025-04-16 17:25:02,653 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,673 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,673 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,674 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,693 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,693 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,709 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,709 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,711 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_15_0.00_embeddings.json
2025-04-16 17:25:02,711 - embedding_process - INFO - 
Processing detection 17/36: tesseract_0_16_0.00
2025-04-16 17:25:02,712 - embedding_process - INFO - Generating embeddings for detection tesseract_0_16_0.00...
2025-04-16 17:25:02,712 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,731 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,732 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,732 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,751 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,752 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,766 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,767 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,769 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_16_0.00_embeddings.json
2025-04-16 17:25:02,769 - embedding_process - INFO - 
Processing detection 18/36: tesseract_0_17_0.00
2025-04-16 17:25:02,770 - embedding_process - INFO - Generating embeddings for detection tesseract_0_17_0.00...
2025-04-16 17:25:02,770 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,790 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,791 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,791 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,812 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,812 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,827 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,828 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,829 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_17_0.00_embeddings.json
2025-04-16 17:25:02,830 - embedding_process - INFO - 
Processing detection 19/36: tesseract_0_18_0.00
2025-04-16 17:25:02,831 - embedding_process - INFO - Generating embeddings for detection tesseract_0_18_0.00...
2025-04-16 17:25:02,831 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,851 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,851 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,852 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,872 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,872 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,887 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,888 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,889 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_18_0.00_embeddings.json
2025-04-16 17:25:02,889 - embedding_process - INFO - 
Processing detection 20/36: tesseract_0_19_0.00
2025-04-16 17:25:02,890 - embedding_process - INFO - Generating embeddings for detection tesseract_0_19_0.00...
2025-04-16 17:25:02,890 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,909 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,910 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,910 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,930 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,930 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:02,944 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,945 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,946 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_19_0.00_embeddings.json
2025-04-16 17:25:02,946 - embedding_process - INFO - 
Processing detection 21/36: tesseract_0_20_0.00
2025-04-16 17:25:02,947 - embedding_process - INFO - Generating embeddings for detection tesseract_0_20_0.00...
2025-04-16 17:25:02,947 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:02,966 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:02,967 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:02,967 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:02,987 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:02,987 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,003 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,004 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,006 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_20_0.00_embeddings.json
2025-04-16 17:25:03,006 - embedding_process - INFO - 
Processing detection 22/36: tesseract_0_21_0.00
2025-04-16 17:25:03,007 - embedding_process - INFO - Generating embeddings for detection tesseract_0_21_0.00...
2025-04-16 17:25:03,007 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,027 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,028 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,028 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,048 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,048 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,063 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,064 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,066 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_21_0.00_embeddings.json
2025-04-16 17:25:03,066 - embedding_process - INFO - 
Processing detection 23/36: tesseract_0_22_0.00
2025-04-16 17:25:03,069 - embedding_process - INFO - Generating embeddings for detection tesseract_0_22_0.00...
2025-04-16 17:25:03,069 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,089 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,090 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,090 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,111 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,111 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,126 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,127 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,129 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_22_0.00_embeddings.json
2025-04-16 17:25:03,129 - embedding_process - INFO - 
Processing detection 24/36: tesseract_0_23_0.00
2025-04-16 17:25:03,131 - embedding_process - INFO - Generating embeddings for detection tesseract_0_23_0.00...
2025-04-16 17:25:03,131 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,151 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,152 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,152 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,173 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,173 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,188 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,189 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,191 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_23_0.00_embeddings.json
2025-04-16 17:25:03,191 - embedding_process - INFO - 
Processing detection 25/36: tesseract_0_24_0.00
2025-04-16 17:25:03,191 - embedding_process - INFO - Generating embeddings for detection tesseract_0_24_0.00...
2025-04-16 17:25:03,191 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,210 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,211 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,211 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,231 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,231 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,245 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,246 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,247 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_24_0.00_embeddings.json
2025-04-16 17:25:03,247 - embedding_process - INFO - 
Processing detection 26/36: tesseract_0_25_0.00
2025-04-16 17:25:03,255 - embedding_process - INFO - Generating embeddings for detection tesseract_0_25_0.00...
2025-04-16 17:25:03,255 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,278 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,278 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,279 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,302 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,302 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,320 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,321 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,322 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_25_0.00_embeddings.json
2025-04-16 17:25:03,322 - embedding_process - INFO - 
Processing detection 27/36: tesseract_0_26_0.00
2025-04-16 17:25:03,325 - embedding_process - INFO - Generating embeddings for detection tesseract_0_26_0.00...
2025-04-16 17:25:03,325 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,345 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,346 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,346 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,367 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,367 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,382 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,383 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,385 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_26_0.00_embeddings.json
2025-04-16 17:25:03,385 - embedding_process - INFO - 
Processing detection 28/36: tesseract_0_27_0.00
2025-04-16 17:25:03,386 - embedding_process - INFO - Generating embeddings for detection tesseract_0_27_0.00...
2025-04-16 17:25:03,386 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,404 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,405 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,405 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,425 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,425 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,439 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,440 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,442 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_27_0.00_embeddings.json
2025-04-16 17:25:03,442 - embedding_process - INFO - 
Processing detection 29/36: tesseract_0_28_0.00
2025-04-16 17:25:03,444 - embedding_process - INFO - Generating embeddings for detection tesseract_0_28_0.00...
2025-04-16 17:25:03,444 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,465 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,466 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,466 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,488 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,488 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,504 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,505 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,507 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_28_0.00_embeddings.json
2025-04-16 17:25:03,507 - embedding_process - INFO - 
Processing detection 30/36: tesseract_0_29_0.00
2025-04-16 17:25:03,508 - embedding_process - INFO - Generating embeddings for detection tesseract_0_29_0.00...
2025-04-16 17:25:03,508 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,527 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,528 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,528 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,549 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,549 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,564 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,565 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,566 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_29_0.00_embeddings.json
2025-04-16 17:25:03,567 - embedding_process - INFO - 
Processing detection 31/36: tesseract_0_30_0.00
2025-04-16 17:25:03,568 - embedding_process - INFO - Generating embeddings for detection tesseract_0_30_0.00...
2025-04-16 17:25:03,568 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,589 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,590 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,590 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,611 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,611 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,626 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,627 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,629 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_30_0.00_embeddings.json
2025-04-16 17:25:03,629 - embedding_process - INFO - 
Processing detection 32/36: tesseract_0_31_0.00
2025-04-16 17:25:03,630 - embedding_process - INFO - Generating embeddings for detection tesseract_0_31_0.00...
2025-04-16 17:25:03,630 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,651 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,652 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,652 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,672 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,672 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,688 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,689 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,690 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_31_0.00_embeddings.json
2025-04-16 17:25:03,690 - embedding_process - INFO - 
Processing detection 33/36: tesseract_0_32_0.00
2025-04-16 17:25:03,691 - embedding_process - INFO - Generating embeddings for detection tesseract_0_32_0.00...
2025-04-16 17:25:03,692 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,711 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,712 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,712 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,732 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,732 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,747 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,748 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,749 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_32_0.00_embeddings.json
2025-04-16 17:25:03,750 - embedding_process - INFO - 
Processing detection 34/36: tesseract_0_33_0.00
2025-04-16 17:25:03,750 - embedding_process - INFO - Generating embeddings for detection tesseract_0_33_0.00...
2025-04-16 17:25:03,751 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,769 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,770 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,770 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,791 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,791 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,805 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,806 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,808 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_33_0.00_embeddings.json
2025-04-16 17:25:03,808 - embedding_process - INFO - 
Processing detection 35/36: tesseract_0_34_0.00
2025-04-16 17:25:03,809 - embedding_process - INFO - Generating embeddings for detection tesseract_0_34_0.00...
2025-04-16 17:25:03,809 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,829 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,830 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,830 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,850 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,850 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,866 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,867 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,868 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_34_0.00_embeddings.json
2025-04-16 17:25:03,868 - embedding_process - INFO - 
Processing detection 36/36: tesseract_0_35_0.00
2025-04-16 17:25:03,869 - embedding_process - INFO - Generating embeddings for detection tesseract_0_35_0.00...
2025-04-16 17:25:03,869 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:03,889 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,890 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,890 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:03,911 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:03,911 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:03,926 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:03,927 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:03,928 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_35_0.00_embeddings.json
2025-04-16 17:25:03,928 - embedding_process - INFO - Embedding generation completed in 2.31 seconds
2025-04-16 17:25:03,929 - embedding_process - INFO - 
Saved summary to results/embeddings_full/tesseract_embeddings_summary.json
2025-04-16 17:25:03,929 - embedding_process - INFO - Total number of processed items: 36
2025-04-16 17:25:03,929 - embedding_process - INFO - 
== Performance Summary ==
2025-04-16 17:25:03,929 - embedding_process - INFO - Total execution time: 18.20 seconds
2025-04-16 17:25:03,929 - embedding_process - INFO - Pipeline processing: 6.87 seconds (37.8%)
2025-04-16 17:25:03,929 - embedding_process - INFO - Embedding generation: 2.31 seconds (12.7%)
2025-04-16 17:25:03,930 - embedding_process - INFO - Processed 1 images with 36 detections
2025-04-16 17:25:03,930 - embedding_process - INFO - Average time per detection: 0.06 seconds
2025-04-16 17:25:42,877 - embedding_process - INFO - === System Information ===
2025-04-16 17:25:42,877 - embedding_process - INFO - PyTorch Version: 2.6.0+cu124
2025-04-16 17:25:42,902 - embedding_process - INFO - CUDA Available: True
2025-04-16 17:25:42,902 - embedding_process - INFO - CUDA Version: 12.4
2025-04-16 17:25:42,923 - embedding_process - INFO - GPU Device: Tesla V100-SXM2-16GB
2025-04-16 17:25:42,923 - embedding_process - INFO - GPU Memory: 16.93 GB
2025-04-16 17:25:42,923 - embedding_process - INFO - NumPy Version: 2.2.4
2025-04-16 17:25:42,923 - embedding_process - INFO - OpenCV Version: 4.11.0
2025-04-16 17:25:42,923 - embedding_process - INFO - === PyTorch Data Types ===
2025-04-16 17:25:42,924 - embedding_process - INFO - BFloat16 is available in this PyTorch version
2025-04-16 17:25:42,924 - embedding_process - INFO - Dtype torch.float32 - test successful on CPU
2025-04-16 17:25:43,079 - embedding_process - INFO - Dtype torch.float32 - test successful on CUDA
2025-04-16 17:25:43,080 - embedding_process - INFO - Dtype torch.float16 - test successful on CPU
2025-04-16 17:25:43,080 - embedding_process - INFO - Dtype torch.float16 - test successful on CUDA
2025-04-16 17:25:43,080 - embedding_process - INFO - Dtype torch.float32 - test successful on CPU
2025-04-16 17:25:43,080 - embedding_process - INFO - Dtype torch.float32 - test successful on CUDA
2025-04-16 17:25:43,080 - embedding_process - INFO - Dtype torch.float64 - test successful on CPU
2025-04-16 17:25:43,081 - embedding_process - INFO - Dtype torch.float64 - test successful on CUDA
2025-04-16 17:25:43,081 - embedding_process - INFO - Dtype torch.int32 - test successful on CPU
2025-04-16 17:25:43,081 - embedding_process - INFO - Dtype torch.int32 - test successful on CUDA
2025-04-16 17:25:43,081 - embedding_process - INFO - Dtype torch.int8 - test successful on CPU
2025-04-16 17:25:43,081 - embedding_process - INFO - Dtype torch.int8 - test successful on CUDA
2025-04-16 17:25:43,081 - embedding_process - INFO - Dtype torch.int16 - test successful on CPU
2025-04-16 17:25:43,082 - embedding_process - INFO - Dtype torch.int16 - test successful on CUDA
2025-04-16 17:25:43,082 - embedding_process - INFO - Dtype torch.int32 - test successful on CPU
2025-04-16 17:25:43,082 - embedding_process - INFO - Dtype torch.int32 - test successful on CUDA
2025-04-16 17:25:43,082 - embedding_process - INFO - Dtype torch.int64 - test successful on CPU
2025-04-16 17:25:43,082 - embedding_process - INFO - Dtype torch.int64 - test successful on CUDA
2025-04-16 17:25:43,082 - embedding_process - INFO - Dtype torch.uint8 - test successful on CPU
2025-04-16 17:25:43,083 - embedding_process - INFO - Dtype torch.uint8 - test successful on CUDA
2025-04-16 17:25:43,083 - embedding_process - INFO - Dtype torch.bool - test successful on CPU
2025-04-16 17:25:43,083 - embedding_process - INFO - Dtype torch.bool - test successful on CUDA
2025-04-16 17:25:43,083 - embedding_process - INFO - Dtype torch.bfloat16 - test successful on CPU
2025-04-16 17:25:43,083 - embedding_process - INFO - Dtype torch.bfloat16 - test successful on CUDA
2025-04-16 17:25:43,084 - embedding_process - INFO - CUDA is available. Using GPU: Tesla V100-SXM2-16GB
2025-04-16 17:25:43,084 - embedding_process - INFO - Processing image: data/tesseract.png
2025-04-16 17:25:43,084 - embedding_process - INFO - Embedding models: clip, vit, resnet50
2025-04-16 17:25:43,084 - embedding_process - INFO - Using device: cuda
2025-04-16 17:25:43,084 - embedding_process - INFO - Initializing detection and segmentation pipeline...
2025-04-16 17:25:48,094 - root - INFO - Loaded checkpoint sucessfully
2025-04-16 17:25:48,539 - embedding_process - INFO - Running detection and segmentation pipeline...
2025-04-16 17:25:51,088 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-04-16 17:25:51,189 - root - INFO - Computing image embeddings for the provided image...
2025-04-16 17:25:51,466 - root - INFO - Image embeddings computed.
2025-04-16 17:25:52,089 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-04-16 17:25:52,121 - root - INFO - Computing image embeddings for the provided image...
2025-04-16 17:25:52,210 - root - INFO - Image embeddings computed.
2025-04-16 17:25:55,474 - embedding_process - INFO - Pipeline completed in 6.94 seconds
2025-04-16 17:25:55,475 - embedding_process - INFO - Initializing embedding generator with models: ['clip', 'vit', 'resnet50']
2025-04-16 17:25:58,180 - embedding_process - INFO - === Embedding Model Details ===
2025-04-16 17:25:58,180 - embedding_process - INFO - Model: ModelType.CLIP
2025-04-16 17:25:58,180 - embedding_process - INFO -   Module text_model.embeddings.token_embedding is on device cuda:0
2025-04-16 17:25:58,180 - embedding_process - INFO -   Module text_model.embeddings.position_embedding is on device cuda:0
2025-04-16 17:25:58,180 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.0.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.0.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.0.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.0.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.0.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,181 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.1.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.1.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.1.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.1.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.1.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.2.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.2.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,182 - embedding_process - INFO -   Module text_model.encoder.layers.2.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.2.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.2.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.3.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.3.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.3.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.3.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,183 - embedding_process - INFO -   Module text_model.encoder.layers.3.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.4.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.4.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.4.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.4.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.4.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,184 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.5.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.5.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.5.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.5.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.5.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.6.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.6.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,185 - embedding_process - INFO -   Module text_model.encoder.layers.6.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,186 - embedding_process - INFO -   Module text_model.encoder.layers.6.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,186 - embedding_process - INFO -   Module text_model.encoder.layers.6.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,186 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,186 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,186 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,186 - embedding_process - INFO -   Module text_model.encoder.layers.7.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,186 - embedding_process - INFO -   Module text_model.encoder.layers.7.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,186 - embedding_process - INFO -   Module text_model.encoder.layers.7.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,186 - embedding_process - INFO -   Module text_model.encoder.layers.7.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,187 - embedding_process - INFO -   Module text_model.encoder.layers.7.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,187 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,187 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,187 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,187 - embedding_process - INFO -   Module text_model.encoder.layers.8.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,187 - embedding_process - INFO -   Module text_model.encoder.layers.8.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,187 - embedding_process - INFO -   Module text_model.encoder.layers.8.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,187 - embedding_process - INFO -   Module text_model.encoder.layers.8.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,188 - embedding_process - INFO -   Module text_model.encoder.layers.8.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,188 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,188 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,188 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,188 - embedding_process - INFO -   Module text_model.encoder.layers.9.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,188 - embedding_process - INFO -   Module text_model.encoder.layers.9.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,188 - embedding_process - INFO -   Module text_model.encoder.layers.9.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,188 - embedding_process - INFO -   Module text_model.encoder.layers.9.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,188 - embedding_process - INFO -   Module text_model.encoder.layers.9.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,189 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,189 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,189 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,189 - embedding_process - INFO -   Module text_model.encoder.layers.10.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,189 - embedding_process - INFO -   Module text_model.encoder.layers.10.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,189 - embedding_process - INFO -   Module text_model.encoder.layers.10.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,189 - embedding_process - INFO -   Module text_model.encoder.layers.10.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,189 - embedding_process - INFO -   Module text_model.encoder.layers.10.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,189 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,190 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,190 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,190 - embedding_process - INFO -   Module text_model.encoder.layers.11.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,190 - embedding_process - INFO -   Module text_model.encoder.layers.11.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,190 - embedding_process - INFO -   Module text_model.encoder.layers.11.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,190 - embedding_process - INFO -   Module text_model.encoder.layers.11.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,190 - embedding_process - INFO -   Module text_model.encoder.layers.11.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,190 - embedding_process - INFO -   Module text_model.final_layer_norm is on device cuda:0
2025-04-16 17:25:58,191 - embedding_process - INFO -   Module vision_model.embeddings.patch_embedding is on device cuda:0
2025-04-16 17:25:58,191 - embedding_process - INFO -   Module vision_model.embeddings.position_embedding is on device cuda:0
2025-04-16 17:25:58,191 - embedding_process - INFO -   Module vision_model.pre_layrnorm is on device cuda:0
2025-04-16 17:25:58,191 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,191 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,191 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,191 - embedding_process - INFO -   Module vision_model.encoder.layers.0.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,191 - embedding_process - INFO -   Module vision_model.encoder.layers.0.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,191 - embedding_process - INFO -   Module vision_model.encoder.layers.0.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.0.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.0.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.1.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.1.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.1.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.1.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.1.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,192 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.2.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.2.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.2.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.2.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.2.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,193 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.3.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.3.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.3.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.3.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.3.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.4.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.4.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,194 - embedding_process - INFO -   Module vision_model.encoder.layers.4.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.4.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.4.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.5.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.5.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.5.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.5.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.5.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,195 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,196 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,196 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,196 - embedding_process - INFO -   Module vision_model.encoder.layers.6.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,196 - embedding_process - INFO -   Module vision_model.encoder.layers.6.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,196 - embedding_process - INFO -   Module vision_model.encoder.layers.6.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,196 - embedding_process - INFO -   Module vision_model.encoder.layers.6.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,196 - embedding_process - INFO -   Module vision_model.encoder.layers.6.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,196 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,196 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.7.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.7.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.7.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.7.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.7.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.8.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,197 - embedding_process - INFO -   Module vision_model.encoder.layers.8.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.8.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.8.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.8.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.9.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.9.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.9.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.9.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,198 - embedding_process - INFO -   Module vision_model.encoder.layers.9.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.10.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.10.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.10.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.10.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.10.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.k_proj is on device cuda:0
2025-04-16 17:25:58,199 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.v_proj is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.q_proj is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module vision_model.encoder.layers.11.self_attn.out_proj is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module vision_model.encoder.layers.11.layer_norm1 is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module vision_model.encoder.layers.11.mlp.fc1 is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module vision_model.encoder.layers.11.mlp.fc2 is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module vision_model.encoder.layers.11.layer_norm2 is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module vision_model.post_layernorm is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module visual_projection is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module text_projection is on device cuda:0
2025-04-16 17:25:58,200 - embedding_process - INFO - Model: ModelType.VIT
2025-04-16 17:25:58,200 - embedding_process - INFO -   Module embeddings.patch_embeddings.projection is on device cuda:0
2025-04-16 17:25:58,201 - embedding_process - INFO -   Module encoder.layer.0.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,201 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,201 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,201 - embedding_process - INFO -   Module encoder.layer.0.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,201 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,201 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,201 - embedding_process - INFO -   Module encoder.layer.0.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,201 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,201 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,202 - embedding_process - INFO -   Module encoder.layer.0.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,202 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,202 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,202 - embedding_process - INFO -   Module encoder.layer.0.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,202 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,202 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,202 - embedding_process - INFO -   Module encoder.layer.0.output.dense is on device cuda:0
2025-04-16 17:25:58,202 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,202 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,202 - embedding_process - INFO -   Module encoder.layer.0.layernorm_before is on device cuda:0
2025-04-16 17:25:58,202 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,203 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,203 - embedding_process - INFO -   Module encoder.layer.0.layernorm_after is on device cuda:0
2025-04-16 17:25:58,203 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,203 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,203 - embedding_process - INFO -   Module encoder.layer.1.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,203 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,203 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,203 - embedding_process - INFO -   Module encoder.layer.1.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,203 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,203 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,203 - embedding_process - INFO -   Module encoder.layer.1.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,203 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,204 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,204 - embedding_process - INFO -   Module encoder.layer.1.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,204 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,204 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,204 - embedding_process - INFO -   Module encoder.layer.1.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,204 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,204 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,204 - embedding_process - INFO -   Module encoder.layer.1.output.dense is on device cuda:0
2025-04-16 17:25:58,204 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,204 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,204 - embedding_process - INFO -   Module encoder.layer.1.layernorm_before is on device cuda:0
2025-04-16 17:25:58,205 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,205 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,205 - embedding_process - INFO -   Module encoder.layer.1.layernorm_after is on device cuda:0
2025-04-16 17:25:58,205 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,205 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,205 - embedding_process - INFO -   Module encoder.layer.2.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,205 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,205 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,205 - embedding_process - INFO -   Module encoder.layer.2.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,205 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,205 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,206 - embedding_process - INFO -   Module encoder.layer.2.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,206 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,206 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,206 - embedding_process - INFO -   Module encoder.layer.2.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,206 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,206 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,206 - embedding_process - INFO -   Module encoder.layer.2.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,206 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,207 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,207 - embedding_process - INFO -   Module encoder.layer.2.output.dense is on device cuda:0
2025-04-16 17:25:58,207 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,207 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,207 - embedding_process - INFO -   Module encoder.layer.2.layernorm_before is on device cuda:0
2025-04-16 17:25:58,207 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,207 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,207 - embedding_process - INFO -   Module encoder.layer.2.layernorm_after is on device cuda:0
2025-04-16 17:25:58,207 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,208 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,208 - embedding_process - INFO -   Module encoder.layer.3.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,208 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,208 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,208 - embedding_process - INFO -   Module encoder.layer.3.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,208 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,208 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,208 - embedding_process - INFO -   Module encoder.layer.3.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,208 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,208 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,209 - embedding_process - INFO -   Module encoder.layer.3.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,209 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,209 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,209 - embedding_process - INFO -   Module encoder.layer.3.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,209 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,209 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,209 - embedding_process - INFO -   Module encoder.layer.3.output.dense is on device cuda:0
2025-04-16 17:25:58,209 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,209 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,210 - embedding_process - INFO -   Module encoder.layer.3.layernorm_before is on device cuda:0
2025-04-16 17:25:58,210 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,210 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,210 - embedding_process - INFO -   Module encoder.layer.3.layernorm_after is on device cuda:0
2025-04-16 17:25:58,210 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,210 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,210 - embedding_process - INFO -   Module encoder.layer.4.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,210 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,210 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,211 - embedding_process - INFO -   Module encoder.layer.4.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,211 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,211 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,211 - embedding_process - INFO -   Module encoder.layer.4.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,211 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,211 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,211 - embedding_process - INFO -   Module encoder.layer.4.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,212 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,212 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,212 - embedding_process - INFO -   Module encoder.layer.4.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,212 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,212 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,212 - embedding_process - INFO -   Module encoder.layer.4.output.dense is on device cuda:0
2025-04-16 17:25:58,212 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,213 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,213 - embedding_process - INFO -   Module encoder.layer.4.layernorm_before is on device cuda:0
2025-04-16 17:25:58,213 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,213 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,213 - embedding_process - INFO -   Module encoder.layer.4.layernorm_after is on device cuda:0
2025-04-16 17:25:58,213 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,213 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,214 - embedding_process - INFO -   Module encoder.layer.5.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,214 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,214 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,214 - embedding_process - INFO -   Module encoder.layer.5.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,214 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,214 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,214 - embedding_process - INFO -   Module encoder.layer.5.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,214 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,215 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,215 - embedding_process - INFO -   Module encoder.layer.5.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,215 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,215 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,215 - embedding_process - INFO -   Module encoder.layer.5.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,215 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,215 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,216 - embedding_process - INFO -   Module encoder.layer.5.output.dense is on device cuda:0
2025-04-16 17:25:58,216 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,216 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,216 - embedding_process - INFO -   Module encoder.layer.5.layernorm_before is on device cuda:0
2025-04-16 17:25:58,216 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,216 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,216 - embedding_process - INFO -   Module encoder.layer.5.layernorm_after is on device cuda:0
2025-04-16 17:25:58,216 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,217 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,217 - embedding_process - INFO -   Module encoder.layer.6.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,217 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,217 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,217 - embedding_process - INFO -   Module encoder.layer.6.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,217 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,217 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,218 - embedding_process - INFO -   Module encoder.layer.6.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,218 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,218 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,218 - embedding_process - INFO -   Module encoder.layer.6.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,218 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,218 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,218 - embedding_process - INFO -   Module encoder.layer.6.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,218 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,219 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,219 - embedding_process - INFO -   Module encoder.layer.6.output.dense is on device cuda:0
2025-04-16 17:25:58,219 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,219 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,219 - embedding_process - INFO -   Module encoder.layer.6.layernorm_before is on device cuda:0
2025-04-16 17:25:58,219 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,219 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,220 - embedding_process - INFO -   Module encoder.layer.6.layernorm_after is on device cuda:0
2025-04-16 17:25:58,220 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,220 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,220 - embedding_process - INFO -   Module encoder.layer.7.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,220 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,220 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,220 - embedding_process - INFO -   Module encoder.layer.7.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,220 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,221 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,221 - embedding_process - INFO -   Module encoder.layer.7.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,221 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,221 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,221 - embedding_process - INFO -   Module encoder.layer.7.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,221 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,221 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,222 - embedding_process - INFO -   Module encoder.layer.7.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,222 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,222 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,222 - embedding_process - INFO -   Module encoder.layer.7.output.dense is on device cuda:0
2025-04-16 17:25:58,222 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,222 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,222 - embedding_process - INFO -   Module encoder.layer.7.layernorm_before is on device cuda:0
2025-04-16 17:25:58,222 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,223 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,223 - embedding_process - INFO -   Module encoder.layer.7.layernorm_after is on device cuda:0
2025-04-16 17:25:58,223 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,223 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,223 - embedding_process - INFO -   Module encoder.layer.8.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,223 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,223 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,224 - embedding_process - INFO -   Module encoder.layer.8.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,224 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,224 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,224 - embedding_process - INFO -   Module encoder.layer.8.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,224 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,224 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,224 - embedding_process - INFO -   Module encoder.layer.8.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,224 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,225 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,225 - embedding_process - INFO -   Module encoder.layer.8.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,225 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,225 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,225 - embedding_process - INFO -   Module encoder.layer.8.output.dense is on device cuda:0
2025-04-16 17:25:58,225 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,225 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,225 - embedding_process - INFO -   Module encoder.layer.8.layernorm_before is on device cuda:0
2025-04-16 17:25:58,226 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,226 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,226 - embedding_process - INFO -   Module encoder.layer.8.layernorm_after is on device cuda:0
2025-04-16 17:25:58,226 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,226 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,226 - embedding_process - INFO -   Module encoder.layer.9.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,226 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,227 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,227 - embedding_process - INFO -   Module encoder.layer.9.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,227 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,227 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,227 - embedding_process - INFO -   Module encoder.layer.9.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,227 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,227 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,228 - embedding_process - INFO -   Module encoder.layer.9.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,228 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,228 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,228 - embedding_process - INFO -   Module encoder.layer.9.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,228 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,228 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,228 - embedding_process - INFO -   Module encoder.layer.9.output.dense is on device cuda:0
2025-04-16 17:25:58,228 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,229 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,229 - embedding_process - INFO -   Module encoder.layer.9.layernorm_before is on device cuda:0
2025-04-16 17:25:58,229 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,229 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,229 - embedding_process - INFO -   Module encoder.layer.9.layernorm_after is on device cuda:0
2025-04-16 17:25:58,229 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,229 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,230 - embedding_process - INFO -   Module encoder.layer.10.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,230 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,230 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,230 - embedding_process - INFO -   Module encoder.layer.10.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,230 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,230 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,230 - embedding_process - INFO -   Module encoder.layer.10.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,230 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,231 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,231 - embedding_process - INFO -   Module encoder.layer.10.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,231 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,231 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,231 - embedding_process - INFO -   Module encoder.layer.10.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,231 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,231 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,232 - embedding_process - INFO -   Module encoder.layer.10.output.dense is on device cuda:0
2025-04-16 17:25:58,232 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,232 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,232 - embedding_process - INFO -   Module encoder.layer.10.layernorm_before is on device cuda:0
2025-04-16 17:25:58,232 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,232 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,232 - embedding_process - INFO -   Module encoder.layer.10.layernorm_after is on device cuda:0
2025-04-16 17:25:58,232 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,233 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,233 - embedding_process - INFO -   Module encoder.layer.11.attention.attention.query is on device cuda:0
2025-04-16 17:25:58,233 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,233 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,233 - embedding_process - INFO -   Module encoder.layer.11.attention.attention.key is on device cuda:0
2025-04-16 17:25:58,233 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,233 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,233 - embedding_process - INFO -   Module encoder.layer.11.attention.attention.value is on device cuda:0
2025-04-16 17:25:58,234 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,234 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,234 - embedding_process - INFO -   Module encoder.layer.11.attention.output.dense is on device cuda:0
2025-04-16 17:25:58,234 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 768]), Type: torch.float32
2025-04-16 17:25:58,234 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,234 - embedding_process - INFO -   Module encoder.layer.11.intermediate.dense is on device cuda:0
2025-04-16 17:25:58,234 - embedding_process - INFO -   Weight - Shape: torch.Size([3072, 768]), Type: torch.float32
2025-04-16 17:25:58,235 - embedding_process - INFO -   Bias - Shape: torch.Size([3072]), Type: torch.float32
2025-04-16 17:25:58,235 - embedding_process - INFO -   Module encoder.layer.11.output.dense is on device cuda:0
2025-04-16 17:25:58,235 - embedding_process - INFO -   Weight - Shape: torch.Size([768, 3072]), Type: torch.float32
2025-04-16 17:25:58,235 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,235 - embedding_process - INFO -   Module encoder.layer.11.layernorm_before is on device cuda:0
2025-04-16 17:25:58,235 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,235 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,235 - embedding_process - INFO -   Module encoder.layer.11.layernorm_after is on device cuda:0
2025-04-16 17:25:58,236 - embedding_process - INFO -   Weight - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,236 - embedding_process - INFO -   Bias - Shape: torch.Size([768]), Type: torch.float32
2025-04-16 17:25:58,236 - embedding_process - INFO -   Module layernorm is on device cuda:0
2025-04-16 17:25:58,236 - embedding_process - INFO -   Module pooler.dense is on device cuda:0
2025-04-16 17:25:58,236 - embedding_process - INFO - Model: ModelType.RESNET50
2025-04-16 17:25:58,236 - embedding_process - INFO -   Module 0 is on device cuda:0
2025-04-16 17:25:58,236 - embedding_process - INFO -   Weight - Shape: torch.Size([64, 3, 7, 7]), Type: torch.float32
2025-04-16 17:25:58,237 - embedding_process - INFO -   Module 1 is on device cuda:0
2025-04-16 17:25:58,237 - embedding_process - INFO -   Weight - Shape: torch.Size([64]), Type: torch.float32
2025-04-16 17:25:58,237 - embedding_process - INFO -   Bias - Shape: torch.Size([64]), Type: torch.float32
2025-04-16 17:25:58,237 - embedding_process - INFO -   Module 4.0.conv1 is on device cuda:0
2025-04-16 17:25:58,237 - embedding_process - INFO -   Module 4.0.bn1 is on device cuda:0
2025-04-16 17:25:58,237 - embedding_process - INFO -   Module 4.0.conv2 is on device cuda:0
2025-04-16 17:25:58,237 - embedding_process - INFO -   Module 4.0.bn2 is on device cuda:0
2025-04-16 17:25:58,238 - embedding_process - INFO -   Module 4.0.conv3 is on device cuda:0
2025-04-16 17:25:58,238 - embedding_process - INFO -   Module 4.0.bn3 is on device cuda:0
2025-04-16 17:25:58,238 - embedding_process - INFO -   Module 4.0.downsample.0 is on device cuda:0
2025-04-16 17:25:58,238 - embedding_process - INFO -   Module 4.0.downsample.1 is on device cuda:0
2025-04-16 17:25:58,238 - embedding_process - INFO -   Module 4.1.conv1 is on device cuda:0
2025-04-16 17:25:58,238 - embedding_process - INFO -   Module 4.1.bn1 is on device cuda:0
2025-04-16 17:25:58,238 - embedding_process - INFO -   Module 4.1.conv2 is on device cuda:0
2025-04-16 17:25:58,238 - embedding_process - INFO -   Module 4.1.bn2 is on device cuda:0
2025-04-16 17:25:58,239 - embedding_process - INFO -   Module 4.1.conv3 is on device cuda:0
2025-04-16 17:25:58,239 - embedding_process - INFO -   Module 4.1.bn3 is on device cuda:0
2025-04-16 17:25:58,239 - embedding_process - INFO -   Module 4.2.conv1 is on device cuda:0
2025-04-16 17:25:58,239 - embedding_process - INFO -   Module 4.2.bn1 is on device cuda:0
2025-04-16 17:25:58,239 - embedding_process - INFO -   Module 4.2.conv2 is on device cuda:0
2025-04-16 17:25:58,239 - embedding_process - INFO -   Module 4.2.bn2 is on device cuda:0
2025-04-16 17:25:58,239 - embedding_process - INFO -   Module 4.2.conv3 is on device cuda:0
2025-04-16 17:25:58,240 - embedding_process - INFO -   Module 4.2.bn3 is on device cuda:0
2025-04-16 17:25:58,240 - embedding_process - INFO -   Module 5.0.conv1 is on device cuda:0
2025-04-16 17:25:58,240 - embedding_process - INFO -   Module 5.0.bn1 is on device cuda:0
2025-04-16 17:25:58,240 - embedding_process - INFO -   Module 5.0.conv2 is on device cuda:0
2025-04-16 17:25:58,240 - embedding_process - INFO -   Module 5.0.bn2 is on device cuda:0
2025-04-16 17:25:58,240 - embedding_process - INFO -   Module 5.0.conv3 is on device cuda:0
2025-04-16 17:25:58,240 - embedding_process - INFO -   Module 5.0.bn3 is on device cuda:0
2025-04-16 17:25:58,241 - embedding_process - INFO -   Module 5.0.downsample.0 is on device cuda:0
2025-04-16 17:25:58,241 - embedding_process - INFO -   Module 5.0.downsample.1 is on device cuda:0
2025-04-16 17:25:58,241 - embedding_process - INFO -   Module 5.1.conv1 is on device cuda:0
2025-04-16 17:25:58,241 - embedding_process - INFO -   Module 5.1.bn1 is on device cuda:0
2025-04-16 17:25:58,241 - embedding_process - INFO -   Module 5.1.conv2 is on device cuda:0
2025-04-16 17:25:58,241 - embedding_process - INFO -   Module 5.1.bn2 is on device cuda:0
2025-04-16 17:25:58,241 - embedding_process - INFO -   Module 5.1.conv3 is on device cuda:0
2025-04-16 17:25:58,241 - embedding_process - INFO -   Module 5.1.bn3 is on device cuda:0
2025-04-16 17:25:58,242 - embedding_process - INFO -   Module 5.2.conv1 is on device cuda:0
2025-04-16 17:25:58,242 - embedding_process - INFO -   Module 5.2.bn1 is on device cuda:0
2025-04-16 17:25:58,242 - embedding_process - INFO -   Module 5.2.conv2 is on device cuda:0
2025-04-16 17:25:58,242 - embedding_process - INFO -   Module 5.2.bn2 is on device cuda:0
2025-04-16 17:25:58,242 - embedding_process - INFO -   Module 5.2.conv3 is on device cuda:0
2025-04-16 17:25:58,242 - embedding_process - INFO -   Module 5.2.bn3 is on device cuda:0
2025-04-16 17:25:58,242 - embedding_process - INFO -   Module 5.3.conv1 is on device cuda:0
2025-04-16 17:25:58,243 - embedding_process - INFO -   Module 5.3.bn1 is on device cuda:0
2025-04-16 17:25:58,243 - embedding_process - INFO -   Module 5.3.conv2 is on device cuda:0
2025-04-16 17:25:58,243 - embedding_process - INFO -   Module 5.3.bn2 is on device cuda:0
2025-04-16 17:25:58,243 - embedding_process - INFO -   Module 5.3.conv3 is on device cuda:0
2025-04-16 17:25:58,243 - embedding_process - INFO -   Module 5.3.bn3 is on device cuda:0
2025-04-16 17:25:58,243 - embedding_process - INFO -   Module 6.0.conv1 is on device cuda:0
2025-04-16 17:25:58,243 - embedding_process - INFO -   Module 6.0.bn1 is on device cuda:0
2025-04-16 17:25:58,244 - embedding_process - INFO -   Module 6.0.conv2 is on device cuda:0
2025-04-16 17:25:58,244 - embedding_process - INFO -   Module 6.0.bn2 is on device cuda:0
2025-04-16 17:25:58,244 - embedding_process - INFO -   Module 6.0.conv3 is on device cuda:0
2025-04-16 17:25:58,244 - embedding_process - INFO -   Module 6.0.bn3 is on device cuda:0
2025-04-16 17:25:58,244 - embedding_process - INFO -   Module 6.0.downsample.0 is on device cuda:0
2025-04-16 17:25:58,244 - embedding_process - INFO -   Module 6.0.downsample.1 is on device cuda:0
2025-04-16 17:25:58,244 - embedding_process - INFO -   Module 6.1.conv1 is on device cuda:0
2025-04-16 17:25:58,245 - embedding_process - INFO -   Module 6.1.bn1 is on device cuda:0
2025-04-16 17:25:58,245 - embedding_process - INFO -   Module 6.1.conv2 is on device cuda:0
2025-04-16 17:25:58,245 - embedding_process - INFO -   Module 6.1.bn2 is on device cuda:0
2025-04-16 17:25:58,245 - embedding_process - INFO -   Module 6.1.conv3 is on device cuda:0
2025-04-16 17:25:58,245 - embedding_process - INFO -   Module 6.1.bn3 is on device cuda:0
2025-04-16 17:25:58,245 - embedding_process - INFO -   Module 6.2.conv1 is on device cuda:0
2025-04-16 17:25:58,245 - embedding_process - INFO -   Module 6.2.bn1 is on device cuda:0
2025-04-16 17:25:58,245 - embedding_process - INFO -   Module 6.2.conv2 is on device cuda:0
2025-04-16 17:25:58,246 - embedding_process - INFO -   Module 6.2.bn2 is on device cuda:0
2025-04-16 17:25:58,246 - embedding_process - INFO -   Module 6.2.conv3 is on device cuda:0
2025-04-16 17:25:58,246 - embedding_process - INFO -   Module 6.2.bn3 is on device cuda:0
2025-04-16 17:25:58,246 - embedding_process - INFO -   Module 6.3.conv1 is on device cuda:0
2025-04-16 17:25:58,246 - embedding_process - INFO -   Module 6.3.bn1 is on device cuda:0
2025-04-16 17:25:58,246 - embedding_process - INFO -   Module 6.3.conv2 is on device cuda:0
2025-04-16 17:25:58,246 - embedding_process - INFO -   Module 6.3.bn2 is on device cuda:0
2025-04-16 17:25:58,247 - embedding_process - INFO -   Module 6.3.conv3 is on device cuda:0
2025-04-16 17:25:58,247 - embedding_process - INFO -   Module 6.3.bn3 is on device cuda:0
2025-04-16 17:25:58,247 - embedding_process - INFO -   Module 6.4.conv1 is on device cuda:0
2025-04-16 17:25:58,247 - embedding_process - INFO -   Module 6.4.bn1 is on device cuda:0
2025-04-16 17:25:58,247 - embedding_process - INFO -   Module 6.4.conv2 is on device cuda:0
2025-04-16 17:25:58,247 - embedding_process - INFO -   Module 6.4.bn2 is on device cuda:0
2025-04-16 17:25:58,247 - embedding_process - INFO -   Module 6.4.conv3 is on device cuda:0
2025-04-16 17:25:58,248 - embedding_process - INFO -   Module 6.4.bn3 is on device cuda:0
2025-04-16 17:25:58,248 - embedding_process - INFO -   Module 6.5.conv1 is on device cuda:0
2025-04-16 17:25:58,248 - embedding_process - INFO -   Module 6.5.bn1 is on device cuda:0
2025-04-16 17:25:58,248 - embedding_process - INFO -   Module 6.5.conv2 is on device cuda:0
2025-04-16 17:25:58,248 - embedding_process - INFO -   Module 6.5.bn2 is on device cuda:0
2025-04-16 17:25:58,248 - embedding_process - INFO -   Module 6.5.conv3 is on device cuda:0
2025-04-16 17:25:58,248 - embedding_process - INFO -   Module 6.5.bn3 is on device cuda:0
2025-04-16 17:25:58,248 - embedding_process - INFO -   Module 7.0.conv1 is on device cuda:0
2025-04-16 17:25:58,249 - embedding_process - INFO -   Module 7.0.bn1 is on device cuda:0
2025-04-16 17:25:58,249 - embedding_process - INFO -   Module 7.0.conv2 is on device cuda:0
2025-04-16 17:25:58,249 - embedding_process - INFO -   Module 7.0.bn2 is on device cuda:0
2025-04-16 17:25:58,249 - embedding_process - INFO -   Module 7.0.conv3 is on device cuda:0
2025-04-16 17:25:58,249 - embedding_process - INFO -   Module 7.0.bn3 is on device cuda:0
2025-04-16 17:25:58,249 - embedding_process - INFO -   Module 7.0.downsample.0 is on device cuda:0
2025-04-16 17:25:58,249 - embedding_process - INFO -   Module 7.0.downsample.1 is on device cuda:0
2025-04-16 17:25:58,250 - embedding_process - INFO -   Module 7.1.conv1 is on device cuda:0
2025-04-16 17:25:58,250 - embedding_process - INFO -   Module 7.1.bn1 is on device cuda:0
2025-04-16 17:25:58,250 - embedding_process - INFO -   Module 7.1.conv2 is on device cuda:0
2025-04-16 17:25:58,250 - embedding_process - INFO -   Module 7.1.bn2 is on device cuda:0
2025-04-16 17:25:58,250 - embedding_process - INFO -   Module 7.1.conv3 is on device cuda:0
2025-04-16 17:25:58,250 - embedding_process - INFO -   Module 7.1.bn3 is on device cuda:0
2025-04-16 17:25:58,250 - embedding_process - INFO -   Module 7.2.conv1 is on device cuda:0
2025-04-16 17:25:58,251 - embedding_process - INFO -   Module 7.2.bn1 is on device cuda:0
2025-04-16 17:25:58,251 - embedding_process - INFO -   Module 7.2.conv2 is on device cuda:0
2025-04-16 17:25:58,251 - embedding_process - INFO -   Module 7.2.bn2 is on device cuda:0
2025-04-16 17:25:58,251 - embedding_process - INFO -   Module 7.2.conv3 is on device cuda:0
2025-04-16 17:25:58,251 - embedding_process - INFO -   Module 7.2.bn3 is on device cuda:0
2025-04-16 17:25:58,251 - embedding_process - INFO - Loading original image: data/tesseract.png
2025-04-16 17:25:58,263 - embedding_process - INFO - Original image shape: (453, 908, 3), dtype: uint8
2025-04-16 17:25:58,263 - embedding_process - DEBUG - Detection results keys: dict_keys(['image', 'image_path', 'boxes', 'scores', 'labels', 'text_queries', 'model_type', 'model_name'])
2025-04-16 17:25:58,263 - embedding_process - INFO - Found 36 detections in the image
2025-04-16 17:25:58,264 - embedding_process - INFO - Generating embeddings for detections...
2025-04-16 17:25:58,264 - embedding_process - INFO - 
Processing detection 1/36: tesseract_0_00_0.00
2025-04-16 17:25:58,264 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,264 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,265 - embedding_process - DEBUG - Converted box: [172   0 908 449], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,265 - embedding_process - DEBUG - Box coordinates after boundary check: [172, 0, 908, 449]
2025-04-16 17:25:58,265 - embedding_process - DEBUG - Extracting crop from coordinates: y=0:449, x=172:908
2025-04-16 17:25:58,265 - embedding_process - DEBUG - Crop shape: (449, 736, 3), dtype: uint8
2025-04-16 17:25:58,284 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_00_0.00_crop.png
2025-04-16 17:25:58,284 - embedding_process - INFO - Generating embeddings for detection tesseract_0_00_0.00...
2025-04-16 17:25:58,284 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,284 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,285 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 449, 736]), Type: torch.float32
2025-04-16 17:25:58,286 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,286 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,321 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,322 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,322 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,322 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,323 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 449, 736]), Type: torch.float32
2025-04-16 17:25:58,323 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,324 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:58,358 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:58,359 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:58,359 - embedding_process - DEBUG -     Sample: [0.025389937683939934, -0.012842921540141106, 0.04319106414914131]...
2025-04-16 17:25:58,359 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:58,359 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,359 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 449, 736]), Type: torch.float32
2025-04-16 17:25:58,360 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,360 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:58,398 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,399 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,399 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:58,401 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_00_0.00_embeddings.json
2025-04-16 17:25:58,401 - embedding_process - INFO - 
Processing detection 2/36: tesseract_0_01_0.00
2025-04-16 17:25:58,401 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,401 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,401 - embedding_process - DEBUG - Converted box: [150   0 468 304], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,402 - embedding_process - DEBUG - Box coordinates after boundary check: [150, 0, 468, 304]
2025-04-16 17:25:58,402 - embedding_process - DEBUG - Extracting crop from coordinates: y=0:304, x=150:468
2025-04-16 17:25:58,402 - embedding_process - DEBUG - Crop shape: (304, 318, 3), dtype: uint8
2025-04-16 17:25:58,407 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_01_0.00_crop.png
2025-04-16 17:25:58,408 - embedding_process - INFO - Generating embeddings for detection tesseract_0_01_0.00...
2025-04-16 17:25:58,408 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,408 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,408 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 304, 318]), Type: torch.float32
2025-04-16 17:25:58,408 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,409 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,432 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,433 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,433 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,433 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,433 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 304, 318]), Type: torch.float32
2025-04-16 17:25:58,434 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,434 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:58,458 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:58,459 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:58,459 - embedding_process - DEBUG -     Sample: [0.0013264407170936465, -0.03430686146020889, 0.06888534873723984]...
2025-04-16 17:25:58,459 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:58,459 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,459 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 304, 318]), Type: torch.float32
2025-04-16 17:25:58,460 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,460 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:58,478 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,479 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,479 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:58,480 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_01_0.00_embeddings.json
2025-04-16 17:25:58,480 - embedding_process - INFO - 
Processing detection 3/36: tesseract_0_02_0.00
2025-04-16 17:25:58,480 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,481 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,481 - embedding_process - DEBUG - Converted box: [156 122 375 291], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,481 - embedding_process - DEBUG - Box coordinates after boundary check: [156, 122, 375, 291]
2025-04-16 17:25:58,481 - embedding_process - DEBUG - Extracting crop from coordinates: y=122:291, x=156:375
2025-04-16 17:25:58,481 - embedding_process - DEBUG - Crop shape: (169, 219, 3), dtype: uint8
2025-04-16 17:25:58,484 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_02_0.00_crop.png
2025-04-16 17:25:58,484 - embedding_process - INFO - Generating embeddings for detection tesseract_0_02_0.00...
2025-04-16 17:25:58,484 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,484 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,484 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 169, 219]), Type: torch.float32
2025-04-16 17:25:58,484 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,485 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,505 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,506 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,506 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,506 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,507 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 169, 219]), Type: torch.float32
2025-04-16 17:25:58,507 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,507 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:58,529 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:58,529 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:58,529 - embedding_process - DEBUG -     Sample: [0.03478657454252243, -0.05481710284948349, 0.050203174352645874]...
2025-04-16 17:25:58,529 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:58,529 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,530 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 169, 219]), Type: torch.float32
2025-04-16 17:25:58,530 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,530 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:58,547 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,547 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,548 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:58,549 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_02_0.00_embeddings.json
2025-04-16 17:25:58,549 - embedding_process - INFO - 
Processing detection 4/36: tesseract_0_03_0.00
2025-04-16 17:25:58,549 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,549 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,550 - embedding_process - DEBUG - Converted box: [ 23 104 425 325], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,550 - embedding_process - DEBUG - Box coordinates after boundary check: [23, 104, 425, 325]
2025-04-16 17:25:58,550 - embedding_process - DEBUG - Extracting crop from coordinates: y=104:325, x=23:425
2025-04-16 17:25:58,550 - embedding_process - DEBUG - Crop shape: (221, 402, 3), dtype: uint8
2025-04-16 17:25:58,555 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_03_0.00_crop.png
2025-04-16 17:25:58,555 - embedding_process - INFO - Generating embeddings for detection tesseract_0_03_0.00...
2025-04-16 17:25:58,556 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,556 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,556 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 221, 402]), Type: torch.float32
2025-04-16 17:25:58,556 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,557 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,580 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,580 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,581 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,581 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,581 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 221, 402]), Type: torch.float32
2025-04-16 17:25:58,581 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,582 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:58,605 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:58,605 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:58,605 - embedding_process - DEBUG -     Sample: [0.006162967532873154, -0.05001239851117134, 0.04574010521173477]...
2025-04-16 17:25:58,605 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:58,605 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,606 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 221, 402]), Type: torch.float32
2025-04-16 17:25:58,606 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,606 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:58,624 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,625 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,625 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:58,627 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_03_0.00_embeddings.json
2025-04-16 17:25:58,627 - embedding_process - INFO - 
Processing detection 5/36: tesseract_0_04_0.00
2025-04-16 17:25:58,627 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,627 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,628 - embedding_process - DEBUG - Converted box: [172  -1 439 141], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,628 - embedding_process - DEBUG - Box coordinates after boundary check: [172, 0, 439, 141]
2025-04-16 17:25:58,628 - embedding_process - DEBUG - Extracting crop from coordinates: y=0:141, x=172:439
2025-04-16 17:25:58,628 - embedding_process - DEBUG - Crop shape: (141, 267, 3), dtype: uint8
2025-04-16 17:25:58,630 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_04_0.00_crop.png
2025-04-16 17:25:58,630 - embedding_process - INFO - Generating embeddings for detection tesseract_0_04_0.00...
2025-04-16 17:25:58,630 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,630 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,631 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 141, 267]), Type: torch.float32
2025-04-16 17:25:58,631 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,631 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,652 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,653 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,654 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,654 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,654 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 141, 267]), Type: torch.float32
2025-04-16 17:25:58,654 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,654 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:58,676 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:58,676 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:58,677 - embedding_process - DEBUG -     Sample: [-0.03852709010243416, -0.04533327370882034, 0.01941247098147869]...
2025-04-16 17:25:58,677 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:58,677 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,677 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 141, 267]), Type: torch.float32
2025-04-16 17:25:58,677 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,678 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:58,694 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,695 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,695 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:58,696 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_04_0.00_embeddings.json
2025-04-16 17:25:58,697 - embedding_process - INFO - 
Processing detection 6/36: tesseract_0_05_0.00
2025-04-16 17:25:58,697 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,697 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,697 - embedding_process - DEBUG - Converted box: [225 182 278 219], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,697 - embedding_process - DEBUG - Box coordinates after boundary check: [225, 182, 278, 219]
2025-04-16 17:25:58,697 - embedding_process - DEBUG - Extracting crop from coordinates: y=182:219, x=225:278
2025-04-16 17:25:58,698 - embedding_process - DEBUG - Crop shape: (37, 53, 3), dtype: uint8
2025-04-16 17:25:58,698 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_05_0.00_crop.png
2025-04-16 17:25:58,698 - embedding_process - INFO - Generating embeddings for detection tesseract_0_05_0.00...
2025-04-16 17:25:58,698 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,698 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,699 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 37, 53]), Type: torch.float32
2025-04-16 17:25:58,699 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,699 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,719 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,720 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,720 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,720 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,720 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 37, 53]), Type: torch.float32
2025-04-16 17:25:58,721 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,721 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:58,741 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:58,742 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:58,742 - embedding_process - DEBUG -     Sample: [-0.020184190943837166, 0.04988028481602669, 0.010666810907423496]...
2025-04-16 17:25:58,742 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:58,742 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,742 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 37, 53]), Type: torch.float32
2025-04-16 17:25:58,742 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,742 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:58,760 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,761 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,761 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:58,763 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_05_0.00_embeddings.json
2025-04-16 17:25:58,763 - embedding_process - INFO - 
Processing detection 7/36: tesseract_0_06_0.00
2025-04-16 17:25:58,763 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,763 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,763 - embedding_process - DEBUG - Converted box: [ 10  84  46 110], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,763 - embedding_process - DEBUG - Box coordinates after boundary check: [10, 84, 46, 110]
2025-04-16 17:25:58,764 - embedding_process - DEBUG - Extracting crop from coordinates: y=84:110, x=10:46
2025-04-16 17:25:58,764 - embedding_process - DEBUG - Crop shape: (26, 36, 3), dtype: uint8
2025-04-16 17:25:58,764 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_06_0.00_crop.png
2025-04-16 17:25:58,764 - embedding_process - INFO - Generating embeddings for detection tesseract_0_06_0.00...
2025-04-16 17:25:58,764 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,764 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,765 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 26, 36]), Type: torch.float32
2025-04-16 17:25:58,765 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,765 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,785 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,785 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,786 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,786 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,786 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 26, 36]), Type: torch.float32
2025-04-16 17:25:58,786 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,786 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:58,807 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:58,807 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:58,807 - embedding_process - DEBUG -     Sample: [-0.038124632090330124, 0.06534863263368607, -0.04608388617634773]...
2025-04-16 17:25:58,807 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:58,807 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,807 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 26, 36]), Type: torch.float32
2025-04-16 17:25:58,807 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,808 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:58,822 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,823 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,823 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:58,824 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_06_0.00_embeddings.json
2025-04-16 17:25:58,825 - embedding_process - INFO - 
Processing detection 8/36: tesseract_0_07_0.00
2025-04-16 17:25:58,825 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,825 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,825 - embedding_process - DEBUG - Converted box: [886 325 908 382], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,825 - embedding_process - DEBUG - Box coordinates after boundary check: [886, 325, 908, 382]
2025-04-16 17:25:58,825 - embedding_process - DEBUG - Extracting crop from coordinates: y=325:382, x=886:908
2025-04-16 17:25:58,826 - embedding_process - DEBUG - Crop shape: (57, 22, 3), dtype: uint8
2025-04-16 17:25:58,826 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_07_0.00_crop.png
2025-04-16 17:25:58,826 - embedding_process - INFO - Generating embeddings for detection tesseract_0_07_0.00...
2025-04-16 17:25:58,826 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,826 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,827 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 57, 22]), Type: torch.float32
2025-04-16 17:25:58,827 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,827 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,847 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,847 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,848 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,848 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,848 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 57, 22]), Type: torch.float32
2025-04-16 17:25:58,848 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,848 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:58,868 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:58,868 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:58,868 - embedding_process - DEBUG -     Sample: [0.003830741858109832, 0.029496898874640465, 0.0011899276869371533]...
2025-04-16 17:25:58,869 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:58,869 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,869 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 57, 22]), Type: torch.float32
2025-04-16 17:25:58,869 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,869 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:58,884 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,885 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,885 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:58,887 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_07_0.00_embeddings.json
2025-04-16 17:25:58,887 - embedding_process - INFO - 
Processing detection 9/36: tesseract_0_08_0.00
2025-04-16 17:25:58,887 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,887 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,887 - embedding_process - DEBUG - Converted box: [425   6 723 283], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,888 - embedding_process - DEBUG - Box coordinates after boundary check: [425, 6, 723, 283]
2025-04-16 17:25:58,888 - embedding_process - DEBUG - Extracting crop from coordinates: y=6:283, x=425:723
2025-04-16 17:25:58,888 - embedding_process - DEBUG - Crop shape: (277, 298, 3), dtype: uint8
2025-04-16 17:25:58,893 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_08_0.00_crop.png
2025-04-16 17:25:58,893 - embedding_process - INFO - Generating embeddings for detection tesseract_0_08_0.00...
2025-04-16 17:25:58,893 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,893 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,894 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 277, 298]), Type: torch.float32
2025-04-16 17:25:58,894 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,894 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,916 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,917 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,917 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,918 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,918 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 277, 298]), Type: torch.float32
2025-04-16 17:25:58,918 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,918 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:58,942 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:58,942 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:58,942 - embedding_process - DEBUG -     Sample: [-0.007607418578118086, -0.011703139171004295, -0.012246008031070232]...
2025-04-16 17:25:58,943 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:58,943 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,943 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 277, 298]), Type: torch.float32
2025-04-16 17:25:58,943 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,944 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:58,961 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,962 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,962 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:58,963 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_08_0.00_embeddings.json
2025-04-16 17:25:58,964 - embedding_process - INFO - 
Processing detection 10/36: tesseract_0_09_0.00
2025-04-16 17:25:58,964 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:58,964 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:58,964 - embedding_process - DEBUG - Converted box: [ -4   0 269 451], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:58,964 - embedding_process - DEBUG - Box coordinates after boundary check: [0, 0, 269, 451]
2025-04-16 17:25:58,964 - embedding_process - DEBUG - Extracting crop from coordinates: y=0:451, x=0:269
2025-04-16 17:25:58,965 - embedding_process - DEBUG - Crop shape: (451, 269, 3), dtype: uint8
2025-04-16 17:25:58,971 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_09_0.00_crop.png
2025-04-16 17:25:58,972 - embedding_process - INFO - Generating embeddings for detection tesseract_0_09_0.00...
2025-04-16 17:25:58,972 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:58,972 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,972 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 451, 269]), Type: torch.float32
2025-04-16 17:25:58,973 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,973 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:58,997 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:58,998 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:58,998 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:58,998 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:58,998 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 451, 269]), Type: torch.float32
2025-04-16 17:25:58,999 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:58,999 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,023 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,023 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,023 - embedding_process - DEBUG -     Sample: [0.017005732282996178, -0.053344856947660446, 0.013318493962287903]...
2025-04-16 17:25:59,024 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,024 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,024 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 451, 269]), Type: torch.float32
2025-04-16 17:25:59,024 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,025 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,043 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,044 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,044 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,046 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_09_0.00_embeddings.json
2025-04-16 17:25:59,046 - embedding_process - INFO - 
Processing detection 11/36: tesseract_0_10_0.00
2025-04-16 17:25:59,046 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,046 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,046 - embedding_process - DEBUG - Converted box: [183 249 276 302], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,046 - embedding_process - DEBUG - Box coordinates after boundary check: [183, 249, 276, 302]
2025-04-16 17:25:59,047 - embedding_process - DEBUG - Extracting crop from coordinates: y=249:302, x=183:276
2025-04-16 17:25:59,047 - embedding_process - DEBUG - Crop shape: (53, 93, 3), dtype: uint8
2025-04-16 17:25:59,047 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_10_0.00_crop.png
2025-04-16 17:25:59,048 - embedding_process - INFO - Generating embeddings for detection tesseract_0_10_0.00...
2025-04-16 17:25:59,048 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,048 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,048 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 53, 93]), Type: torch.float32
2025-04-16 17:25:59,048 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,048 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,068 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,069 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,069 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,069 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,069 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 53, 93]), Type: torch.float32
2025-04-16 17:25:59,070 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,070 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,090 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,090 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,091 - embedding_process - DEBUG -     Sample: [0.0023663686588406563, -0.022507652640342712, 0.03583589196205139]...
2025-04-16 17:25:59,091 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,091 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,091 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 53, 93]), Type: torch.float32
2025-04-16 17:25:59,091 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,091 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,107 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,108 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,108 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,109 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_10_0.00_embeddings.json
2025-04-16 17:25:59,109 - embedding_process - INFO - 
Processing detection 12/36: tesseract_0_11_0.00
2025-04-16 17:25:59,110 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,110 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,110 - embedding_process - DEBUG - Converted box: [186   5 289 116], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,110 - embedding_process - DEBUG - Box coordinates after boundary check: [186, 5, 289, 116]
2025-04-16 17:25:59,110 - embedding_process - DEBUG - Extracting crop from coordinates: y=5:116, x=186:289
2025-04-16 17:25:59,111 - embedding_process - DEBUG - Crop shape: (111, 103, 3), dtype: uint8
2025-04-16 17:25:59,112 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_11_0.00_crop.png
2025-04-16 17:25:59,112 - embedding_process - INFO - Generating embeddings for detection tesseract_0_11_0.00...
2025-04-16 17:25:59,112 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,112 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,112 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 111, 103]), Type: torch.float32
2025-04-16 17:25:59,112 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,113 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,132 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,133 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,133 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,133 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,133 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 111, 103]), Type: torch.float32
2025-04-16 17:25:59,134 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,134 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,155 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,155 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,155 - embedding_process - DEBUG -     Sample: [-0.003625935409218073, 0.03306961804628372, -0.034834571182727814]...
2025-04-16 17:25:59,155 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,155 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,155 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 111, 103]), Type: torch.float32
2025-04-16 17:25:59,156 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,156 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,171 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,171 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,172 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,173 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_11_0.00_embeddings.json
2025-04-16 17:25:59,173 - embedding_process - INFO - 
Processing detection 13/36: tesseract_0_12_0.00
2025-04-16 17:25:59,173 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,174 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,174 - embedding_process - DEBUG - Converted box: [ -1  66  69 288], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,174 - embedding_process - DEBUG - Box coordinates after boundary check: [0, 66, 69, 288]
2025-04-16 17:25:59,174 - embedding_process - DEBUG - Extracting crop from coordinates: y=66:288, x=0:69
2025-04-16 17:25:59,174 - embedding_process - DEBUG - Crop shape: (222, 69, 3), dtype: uint8
2025-04-16 17:25:59,176 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_12_0.00_crop.png
2025-04-16 17:25:59,176 - embedding_process - INFO - Generating embeddings for detection tesseract_0_12_0.00...
2025-04-16 17:25:59,176 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,176 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,176 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 222, 69]), Type: torch.float32
2025-04-16 17:25:59,177 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,177 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,198 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,199 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,199 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,200 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,200 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 222, 69]), Type: torch.float32
2025-04-16 17:25:59,200 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,200 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,221 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,221 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,222 - embedding_process - DEBUG -     Sample: [-0.04742389917373657, 0.01735745742917061, 0.009225371293723583]...
2025-04-16 17:25:59,222 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,222 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,222 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 222, 69]), Type: torch.float32
2025-04-16 17:25:59,222 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,223 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,239 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,240 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,240 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,241 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_12_0.00_embeddings.json
2025-04-16 17:25:59,242 - embedding_process - INFO - 
Processing detection 14/36: tesseract_0_13_0.00
2025-04-16 17:25:59,242 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,242 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,242 - embedding_process - DEBUG - Converted box: [  0   0 234 152], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,242 - embedding_process - DEBUG - Box coordinates after boundary check: [0, 0, 234, 152]
2025-04-16 17:25:59,242 - embedding_process - DEBUG - Extracting crop from coordinates: y=0:152, x=0:234
2025-04-16 17:25:59,243 - embedding_process - DEBUG - Crop shape: (152, 234, 3), dtype: uint8
2025-04-16 17:25:59,245 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_13_0.00_crop.png
2025-04-16 17:25:59,245 - embedding_process - INFO - Generating embeddings for detection tesseract_0_13_0.00...
2025-04-16 17:25:59,245 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,245 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,246 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 152, 234]), Type: torch.float32
2025-04-16 17:25:59,246 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,246 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,267 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,268 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,269 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,269 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,269 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 152, 234]), Type: torch.float32
2025-04-16 17:25:59,269 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,269 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,291 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,292 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,292 - embedding_process - DEBUG -     Sample: [-0.033459898084402084, -0.01986357942223549, -0.003294330323114991]...
2025-04-16 17:25:59,292 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,292 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,292 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 152, 234]), Type: torch.float32
2025-04-16 17:25:59,293 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,293 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,310 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,311 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,311 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,312 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_13_0.00_embeddings.json
2025-04-16 17:25:59,313 - embedding_process - INFO - 
Processing detection 15/36: tesseract_0_14_0.00
2025-04-16 17:25:59,313 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,313 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,313 - embedding_process - DEBUG - Converted box: [232 253 893 453], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,313 - embedding_process - DEBUG - Box coordinates after boundary check: [232, 253, 893, 453]
2025-04-16 17:25:59,313 - embedding_process - DEBUG - Extracting crop from coordinates: y=253:453, x=232:893
2025-04-16 17:25:59,314 - embedding_process - DEBUG - Crop shape: (200, 661, 3), dtype: uint8
2025-04-16 17:25:59,321 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_14_0.00_crop.png
2025-04-16 17:25:59,321 - embedding_process - INFO - Generating embeddings for detection tesseract_0_14_0.00...
2025-04-16 17:25:59,321 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,321 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,322 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 200, 661]), Type: torch.float32
2025-04-16 17:25:59,322 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,323 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,349 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,350 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,350 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,350 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,350 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 200, 661]), Type: torch.float32
2025-04-16 17:25:59,351 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,351 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,375 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,376 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,376 - embedding_process - DEBUG -     Sample: [0.027976971119642258, -0.028036070987582207, 0.06643187254667282]...
2025-04-16 17:25:59,376 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,376 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,376 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 200, 661]), Type: torch.float32
2025-04-16 17:25:59,377 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,377 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,397 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,398 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,398 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,400 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_14_0.00_embeddings.json
2025-04-16 17:25:59,400 - embedding_process - INFO - 
Processing detection 16/36: tesseract_0_15_0.00
2025-04-16 17:25:59,400 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,400 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,400 - embedding_process - DEBUG - Converted box: [246 189 274 288], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,401 - embedding_process - DEBUG - Box coordinates after boundary check: [246, 189, 274, 288]
2025-04-16 17:25:59,401 - embedding_process - DEBUG - Extracting crop from coordinates: y=189:288, x=246:274
2025-04-16 17:25:59,401 - embedding_process - DEBUG - Crop shape: (99, 28, 3), dtype: uint8
2025-04-16 17:25:59,401 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_15_0.00_crop.png
2025-04-16 17:25:59,402 - embedding_process - INFO - Generating embeddings for detection tesseract_0_15_0.00...
2025-04-16 17:25:59,402 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,402 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,402 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 99, 28]), Type: torch.float32
2025-04-16 17:25:59,402 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,402 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,423 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,424 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,424 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,424 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,425 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 99, 28]), Type: torch.float32
2025-04-16 17:25:59,425 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,425 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,445 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,445 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,445 - embedding_process - DEBUG -     Sample: [-0.05271587148308754, 0.03419634699821472, 0.011326868087053299]...
2025-04-16 17:25:59,446 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,446 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,446 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 99, 28]), Type: torch.float32
2025-04-16 17:25:59,446 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,446 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,462 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,463 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,463 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,465 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_15_0.00_embeddings.json
2025-04-16 17:25:59,465 - embedding_process - INFO - 
Processing detection 17/36: tesseract_0_16_0.00
2025-04-16 17:25:59,465 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,465 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,465 - embedding_process - DEBUG - Converted box: [134   0 211  33], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,465 - embedding_process - DEBUG - Box coordinates after boundary check: [134, 0, 211, 33]
2025-04-16 17:25:59,466 - embedding_process - DEBUG - Extracting crop from coordinates: y=0:33, x=134:211
2025-04-16 17:25:59,466 - embedding_process - DEBUG - Crop shape: (33, 77, 3), dtype: uint8
2025-04-16 17:25:59,466 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_16_0.00_crop.png
2025-04-16 17:25:59,466 - embedding_process - INFO - Generating embeddings for detection tesseract_0_16_0.00...
2025-04-16 17:25:59,466 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,466 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,467 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 33, 77]), Type: torch.float32
2025-04-16 17:25:59,467 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,467 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,486 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,487 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,487 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,487 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,488 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 33, 77]), Type: torch.float32
2025-04-16 17:25:59,488 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,488 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,508 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,508 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,508 - embedding_process - DEBUG -     Sample: [-0.03721751272678375, 0.026886362582445145, -0.0082349618896842]...
2025-04-16 17:25:59,508 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,509 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,509 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 33, 77]), Type: torch.float32
2025-04-16 17:25:59,509 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,509 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,524 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,525 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,525 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,527 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_16_0.00_embeddings.json
2025-04-16 17:25:59,527 - embedding_process - INFO - 
Processing detection 18/36: tesseract_0_17_0.00
2025-04-16 17:25:59,527 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,527 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,527 - embedding_process - DEBUG - Converted box: [163 127 365 203], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,527 - embedding_process - DEBUG - Box coordinates after boundary check: [163, 127, 365, 203]
2025-04-16 17:25:59,528 - embedding_process - DEBUG - Extracting crop from coordinates: y=127:203, x=163:365
2025-04-16 17:25:59,528 - embedding_process - DEBUG - Crop shape: (76, 202, 3), dtype: uint8
2025-04-16 17:25:59,529 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_17_0.00_crop.png
2025-04-16 17:25:59,529 - embedding_process - INFO - Generating embeddings for detection tesseract_0_17_0.00...
2025-04-16 17:25:59,529 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,529 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,529 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 76, 202]), Type: torch.float32
2025-04-16 17:25:59,530 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,530 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,551 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,552 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,552 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,552 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,552 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 76, 202]), Type: torch.float32
2025-04-16 17:25:59,553 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,553 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,574 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,574 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,574 - embedding_process - DEBUG -     Sample: [-0.035556238144636154, -0.01333172433078289, 0.049006137996912]...
2025-04-16 17:25:59,574 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,574 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,575 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 76, 202]), Type: torch.float32
2025-04-16 17:25:59,575 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,575 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,592 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,593 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,593 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,595 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_17_0.00_embeddings.json
2025-04-16 17:25:59,595 - embedding_process - INFO - 
Processing detection 19/36: tesseract_0_18_0.00
2025-04-16 17:25:59,595 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,595 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,595 - embedding_process - DEBUG - Converted box: [173 253 347 345], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,596 - embedding_process - DEBUG - Box coordinates after boundary check: [173, 253, 347, 345]
2025-04-16 17:25:59,596 - embedding_process - DEBUG - Extracting crop from coordinates: y=253:345, x=173:347
2025-04-16 17:25:59,596 - embedding_process - DEBUG - Crop shape: (92, 174, 3), dtype: uint8
2025-04-16 17:25:59,597 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_18_0.00_crop.png
2025-04-16 17:25:59,597 - embedding_process - INFO - Generating embeddings for detection tesseract_0_18_0.00...
2025-04-16 17:25:59,597 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,598 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,598 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 92, 174]), Type: torch.float32
2025-04-16 17:25:59,598 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,598 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,619 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,620 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,620 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,620 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,620 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 92, 174]), Type: torch.float32
2025-04-16 17:25:59,620 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,621 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,642 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,642 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,642 - embedding_process - DEBUG -     Sample: [-0.029780313372612, 0.008665420114994049, 0.028381073847413063]...
2025-04-16 17:25:59,642 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,642 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,642 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 92, 174]), Type: torch.float32
2025-04-16 17:25:59,643 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,643 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,659 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,659 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,660 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,661 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_18_0.00_embeddings.json
2025-04-16 17:25:59,661 - embedding_process - INFO - 
Processing detection 20/36: tesseract_0_19_0.00
2025-04-16 17:25:59,661 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,662 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,662 - embedding_process - DEBUG - Converted box: [  0  51  55 123], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,662 - embedding_process - DEBUG - Box coordinates after boundary check: [0, 51, 55, 123]
2025-04-16 17:25:59,662 - embedding_process - DEBUG - Extracting crop from coordinates: y=51:123, x=0:55
2025-04-16 17:25:59,662 - embedding_process - DEBUG - Crop shape: (72, 55, 3), dtype: uint8
2025-04-16 17:25:59,663 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_19_0.00_crop.png
2025-04-16 17:25:59,663 - embedding_process - INFO - Generating embeddings for detection tesseract_0_19_0.00...
2025-04-16 17:25:59,663 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,663 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,664 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 72, 55]), Type: torch.float32
2025-04-16 17:25:59,664 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,664 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,683 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,684 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,684 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,684 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,685 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 72, 55]), Type: torch.float32
2025-04-16 17:25:59,685 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,685 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,705 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,705 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,705 - embedding_process - DEBUG -     Sample: [-0.036251433193683624, 0.04668717831373215, -0.0005799487698823214]...
2025-04-16 17:25:59,706 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,706 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,706 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 72, 55]), Type: torch.float32
2025-04-16 17:25:59,706 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,706 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,721 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,722 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,722 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,724 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_19_0.00_embeddings.json
2025-04-16 17:25:59,724 - embedding_process - INFO - 
Processing detection 21/36: tesseract_0_20_0.00
2025-04-16 17:25:59,724 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,724 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,724 - embedding_process - DEBUG - Converted box: [893 330 922 366], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,725 - embedding_process - DEBUG - Box coordinates after boundary check: [893, 330, 908, 366]
2025-04-16 17:25:59,725 - embedding_process - DEBUG - Extracting crop from coordinates: y=330:366, x=893:908
2025-04-16 17:25:59,725 - embedding_process - DEBUG - Crop shape: (36, 15, 3), dtype: uint8
2025-04-16 17:25:59,725 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_20_0.00_crop.png
2025-04-16 17:25:59,725 - embedding_process - INFO - Generating embeddings for detection tesseract_0_20_0.00...
2025-04-16 17:25:59,726 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,726 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,726 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 36, 15]), Type: torch.float32
2025-04-16 17:25:59,726 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,726 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,746 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,747 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,747 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,747 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,747 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 36, 15]), Type: torch.float32
2025-04-16 17:25:59,747 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,748 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,768 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,768 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,768 - embedding_process - DEBUG -     Sample: [0.007157260086387396, 0.027076467871665955, -0.010510541498661041]...
2025-04-16 17:25:59,768 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,769 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,769 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 36, 15]), Type: torch.float32
2025-04-16 17:25:59,769 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,769 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,784 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,785 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,786 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,787 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_20_0.00_embeddings.json
2025-04-16 17:25:59,787 - embedding_process - INFO - 
Processing detection 22/36: tesseract_0_21_0.00
2025-04-16 17:25:59,787 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,787 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,788 - embedding_process - DEBUG - Converted box: [716 167 908 247], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,788 - embedding_process - DEBUG - Box coordinates after boundary check: [716, 167, 908, 247]
2025-04-16 17:25:59,788 - embedding_process - DEBUG - Extracting crop from coordinates: y=167:247, x=716:908
2025-04-16 17:25:59,788 - embedding_process - DEBUG - Crop shape: (80, 192, 3), dtype: uint8
2025-04-16 17:25:59,789 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_21_0.00_crop.png
2025-04-16 17:25:59,789 - embedding_process - INFO - Generating embeddings for detection tesseract_0_21_0.00...
2025-04-16 17:25:59,789 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,790 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,790 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 80, 192]), Type: torch.float32
2025-04-16 17:25:59,790 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,790 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,812 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,813 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,814 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,814 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,814 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 80, 192]), Type: torch.float32
2025-04-16 17:25:59,814 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,815 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,836 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,836 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,836 - embedding_process - DEBUG -     Sample: [-0.05751274898648262, -0.0018076896667480469, -0.017712246626615524]...
2025-04-16 17:25:59,837 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,837 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,837 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 80, 192]), Type: torch.float32
2025-04-16 17:25:59,837 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,837 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,856 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,857 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,858 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,860 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_21_0.00_embeddings.json
2025-04-16 17:25:59,861 - embedding_process - INFO - 
Processing detection 23/36: tesseract_0_22_0.00
2025-04-16 17:25:59,861 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,861 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,861 - embedding_process - DEBUG - Converted box: [ 18 118 248 318], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,861 - embedding_process - DEBUG - Box coordinates after boundary check: [18, 118, 248, 318]
2025-04-16 17:25:59,862 - embedding_process - DEBUG - Extracting crop from coordinates: y=118:318, x=18:248
2025-04-16 17:25:59,862 - embedding_process - DEBUG - Crop shape: (200, 230, 3), dtype: uint8
2025-04-16 17:25:59,865 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_22_0.00_crop.png
2025-04-16 17:25:59,865 - embedding_process - INFO - Generating embeddings for detection tesseract_0_22_0.00...
2025-04-16 17:25:59,865 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,865 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,866 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 200, 230]), Type: torch.float32
2025-04-16 17:25:59,866 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,866 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,888 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,889 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,889 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,889 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,890 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 200, 230]), Type: torch.float32
2025-04-16 17:25:59,890 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,890 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,914 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,914 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,914 - embedding_process - DEBUG -     Sample: [-0.019547872245311737, -0.02403692714869976, 0.01593659445643425]...
2025-04-16 17:25:59,914 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,914 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,915 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 200, 230]), Type: torch.float32
2025-04-16 17:25:59,915 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,915 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:25:59,932 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,933 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,933 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:25:59,934 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_22_0.00_embeddings.json
2025-04-16 17:25:59,935 - embedding_process - INFO - 
Processing detection 24/36: tesseract_0_23_0.00
2025-04-16 17:25:59,935 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:25:59,935 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:25:59,935 - embedding_process - DEBUG - Converted box: [445  40 666 173], Type: <class 'numpy.ndarray'>
2025-04-16 17:25:59,935 - embedding_process - DEBUG - Box coordinates after boundary check: [445, 40, 666, 173]
2025-04-16 17:25:59,935 - embedding_process - DEBUG - Extracting crop from coordinates: y=40:173, x=445:666
2025-04-16 17:25:59,936 - embedding_process - DEBUG - Crop shape: (133, 221, 3), dtype: uint8
2025-04-16 17:25:59,937 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_23_0.00_crop.png
2025-04-16 17:25:59,938 - embedding_process - INFO - Generating embeddings for detection tesseract_0_23_0.00...
2025-04-16 17:25:59,938 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:25:59,938 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,938 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 133, 221]), Type: torch.float32
2025-04-16 17:25:59,938 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,939 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:25:59,960 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:25:59,961 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:25:59,961 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:25:59,961 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,961 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 133, 221]), Type: torch.float32
2025-04-16 17:25:59,961 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,961 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:25:59,983 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:25:59,983 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:25:59,984 - embedding_process - DEBUG -     Sample: [0.008271344006061554, -0.03618970885872841, 0.01707167737185955]...
2025-04-16 17:25:59,984 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:25:59,984 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:25:59,984 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 133, 221]), Type: torch.float32
2025-04-16 17:25:59,985 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:25:59,985 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,008 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,010 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,010 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,012 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_23_0.00_embeddings.json
2025-04-16 17:26:00,012 - embedding_process - INFO - 
Processing detection 25/36: tesseract_0_24_0.00
2025-04-16 17:26:00,012 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,012 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,013 - embedding_process - DEBUG - Converted box: [851 187 908 226], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,013 - embedding_process - DEBUG - Box coordinates after boundary check: [851, 187, 908, 226]
2025-04-16 17:26:00,013 - embedding_process - DEBUG - Extracting crop from coordinates: y=187:226, x=851:908
2025-04-16 17:26:00,013 - embedding_process - DEBUG - Crop shape: (39, 57, 3), dtype: uint8
2025-04-16 17:26:00,013 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_24_0.00_crop.png
2025-04-16 17:26:00,014 - embedding_process - INFO - Generating embeddings for detection tesseract_0_24_0.00...
2025-04-16 17:26:00,014 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,014 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,014 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 39, 57]), Type: torch.float32
2025-04-16 17:26:00,014 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,015 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,035 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,035 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,036 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,036 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,036 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 39, 57]), Type: torch.float32
2025-04-16 17:26:00,036 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,036 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,057 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,057 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,057 - embedding_process - DEBUG -     Sample: [-0.03977848216891289, 0.056623950600624084, -0.03033931367099285]...
2025-04-16 17:26:00,058 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,058 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,058 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 39, 57]), Type: torch.float32
2025-04-16 17:26:00,058 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,058 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,073 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,074 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,074 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,076 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_24_0.00_embeddings.json
2025-04-16 17:26:00,076 - embedding_process - INFO - 
Processing detection 26/36: tesseract_0_25_0.00
2025-04-16 17:26:00,076 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,076 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,077 - embedding_process - DEBUG - Converted box: [178 164 588 453], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,077 - embedding_process - DEBUG - Box coordinates after boundary check: [178, 164, 588, 453]
2025-04-16 17:26:00,077 - embedding_process - DEBUG - Extracting crop from coordinates: y=164:453, x=178:588
2025-04-16 17:26:00,077 - embedding_process - DEBUG - Crop shape: (289, 410, 3), dtype: uint8
2025-04-16 17:26:00,084 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_25_0.00_crop.png
2025-04-16 17:26:00,084 - embedding_process - INFO - Generating embeddings for detection tesseract_0_25_0.00...
2025-04-16 17:26:00,084 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,085 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,085 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 289, 410]), Type: torch.float32
2025-04-16 17:26:00,085 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,085 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,110 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,110 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,111 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,111 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,111 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 289, 410]), Type: torch.float32
2025-04-16 17:26:00,112 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,112 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,136 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,136 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,136 - embedding_process - DEBUG -     Sample: [-0.014045733958482742, -0.03759230300784111, 0.006513551343232393]...
2025-04-16 17:26:00,136 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,137 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,137 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 289, 410]), Type: torch.float32
2025-04-16 17:26:00,137 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,137 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,156 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,157 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,157 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,159 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_25_0.00_embeddings.json
2025-04-16 17:26:00,159 - embedding_process - INFO - 
Processing detection 27/36: tesseract_0_26_0.00
2025-04-16 17:26:00,159 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,159 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,160 - embedding_process - DEBUG - Converted box: [173 263 354 451], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,160 - embedding_process - DEBUG - Box coordinates after boundary check: [173, 263, 354, 451]
2025-04-16 17:26:00,160 - embedding_process - DEBUG - Extracting crop from coordinates: y=263:451, x=173:354
2025-04-16 17:26:00,160 - embedding_process - DEBUG - Crop shape: (188, 181, 3), dtype: uint8
2025-04-16 17:26:00,163 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_26_0.00_crop.png
2025-04-16 17:26:00,163 - embedding_process - INFO - Generating embeddings for detection tesseract_0_26_0.00...
2025-04-16 17:26:00,163 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,163 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,163 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 188, 181]), Type: torch.float32
2025-04-16 17:26:00,164 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,164 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,185 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,186 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,186 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,186 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,186 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 188, 181]), Type: torch.float32
2025-04-16 17:26:00,186 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,187 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,209 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,209 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,209 - embedding_process - DEBUG -     Sample: [0.005623682867735624, -0.028032436966896057, 0.08748086541891098]...
2025-04-16 17:26:00,209 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,209 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,209 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 188, 181]), Type: torch.float32
2025-04-16 17:26:00,210 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,210 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,226 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,227 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,227 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,229 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_26_0.00_embeddings.json
2025-04-16 17:26:00,229 - embedding_process - INFO - 
Processing detection 28/36: tesseract_0_27_0.00
2025-04-16 17:26:00,229 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,229 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,230 - embedding_process - DEBUG - Converted box: [521 160 578 218], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,230 - embedding_process - DEBUG - Box coordinates after boundary check: [521, 160, 578, 218]
2025-04-16 17:26:00,230 - embedding_process - DEBUG - Extracting crop from coordinates: y=160:218, x=521:578
2025-04-16 17:26:00,230 - embedding_process - DEBUG - Crop shape: (58, 57, 3), dtype: uint8
2025-04-16 17:26:00,231 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_27_0.00_crop.png
2025-04-16 17:26:00,231 - embedding_process - INFO - Generating embeddings for detection tesseract_0_27_0.00...
2025-04-16 17:26:00,231 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,231 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,231 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 58, 57]), Type: torch.float32
2025-04-16 17:26:00,231 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,231 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,251 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,252 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,252 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,252 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,252 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 58, 57]), Type: torch.float32
2025-04-16 17:26:00,252 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,252 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,273 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,273 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,273 - embedding_process - DEBUG -     Sample: [-0.018167855218052864, -0.0166380126029253, -0.016411663964390755]...
2025-04-16 17:26:00,273 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,273 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,273 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 58, 57]), Type: torch.float32
2025-04-16 17:26:00,274 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,274 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,289 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,289 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,290 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,291 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_27_0.00_embeddings.json
2025-04-16 17:26:00,291 - embedding_process - INFO - 
Processing detection 29/36: tesseract_0_28_0.00
2025-04-16 17:26:00,291 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,292 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,292 - embedding_process - DEBUG - Converted box: [751 224 908 451], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,292 - embedding_process - DEBUG - Box coordinates after boundary check: [751, 224, 908, 451]
2025-04-16 17:26:00,292 - embedding_process - DEBUG - Extracting crop from coordinates: y=224:451, x=751:908
2025-04-16 17:26:00,292 - embedding_process - DEBUG - Crop shape: (227, 157, 3), dtype: uint8
2025-04-16 17:26:00,294 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_28_0.00_crop.png
2025-04-16 17:26:00,295 - embedding_process - INFO - Generating embeddings for detection tesseract_0_28_0.00...
2025-04-16 17:26:00,295 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,295 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,295 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 227, 157]), Type: torch.float32
2025-04-16 17:26:00,295 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,295 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,317 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,317 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,318 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,318 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,318 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 227, 157]), Type: torch.float32
2025-04-16 17:26:00,318 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,318 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,341 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,341 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,341 - embedding_process - DEBUG -     Sample: [0.027185514569282532, 0.010892725549638271, -0.0026684829499572515]...
2025-04-16 17:26:00,341 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,341 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,341 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 227, 157]), Type: torch.float32
2025-04-16 17:26:00,342 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,342 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,359 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,360 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,360 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,361 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_28_0.00_embeddings.json
2025-04-16 17:26:00,362 - embedding_process - INFO - 
Processing detection 30/36: tesseract_0_29_0.00
2025-04-16 17:26:00,362 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,362 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,362 - embedding_process - DEBUG - Converted box: [407 154 450 223], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,362 - embedding_process - DEBUG - Box coordinates after boundary check: [407, 154, 450, 223]
2025-04-16 17:26:00,362 - embedding_process - DEBUG - Extracting crop from coordinates: y=154:223, x=407:450
2025-04-16 17:26:00,363 - embedding_process - DEBUG - Crop shape: (69, 43, 3), dtype: uint8
2025-04-16 17:26:00,363 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_29_0.00_crop.png
2025-04-16 17:26:00,363 - embedding_process - INFO - Generating embeddings for detection tesseract_0_29_0.00...
2025-04-16 17:26:00,363 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,363 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,364 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 69, 43]), Type: torch.float32
2025-04-16 17:26:00,364 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,364 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,384 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,385 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,385 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,385 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,385 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 69, 43]), Type: torch.float32
2025-04-16 17:26:00,386 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,386 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,407 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,407 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,407 - embedding_process - DEBUG -     Sample: [-0.012158328667283058, 0.025885073468089104, 0.0077805607579648495]...
2025-04-16 17:26:00,407 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,407 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,407 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 69, 43]), Type: torch.float32
2025-04-16 17:26:00,408 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,408 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,423 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,424 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,424 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,426 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_29_0.00_embeddings.json
2025-04-16 17:26:00,426 - embedding_process - INFO - 
Processing detection 31/36: tesseract_0_30_0.00
2025-04-16 17:26:00,426 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,427 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,427 - embedding_process - DEBUG - Converted box: [202  53 393 135], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,427 - embedding_process - DEBUG - Box coordinates after boundary check: [202, 53, 393, 135]
2025-04-16 17:26:00,427 - embedding_process - DEBUG - Extracting crop from coordinates: y=53:135, x=202:393
2025-04-16 17:26:00,427 - embedding_process - DEBUG - Crop shape: (82, 191, 3), dtype: uint8
2025-04-16 17:26:00,428 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_30_0.00_crop.png
2025-04-16 17:26:00,429 - embedding_process - INFO - Generating embeddings for detection tesseract_0_30_0.00...
2025-04-16 17:26:00,429 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,429 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,429 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 82, 191]), Type: torch.float32
2025-04-16 17:26:00,429 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,430 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,451 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,452 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,452 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,452 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,453 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 82, 191]), Type: torch.float32
2025-04-16 17:26:00,453 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,453 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,475 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,475 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,476 - embedding_process - DEBUG -     Sample: [-0.024208825081586838, -0.03447762876749039, 0.032063137739896774]...
2025-04-16 17:26:00,476 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,476 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,476 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 82, 191]), Type: torch.float32
2025-04-16 17:26:00,476 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,477 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,493 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,494 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,494 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,495 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_30_0.00_embeddings.json
2025-04-16 17:26:00,495 - embedding_process - INFO - 
Processing detection 32/36: tesseract_0_31_0.00
2025-04-16 17:26:00,496 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,496 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,496 - embedding_process - DEBUG - Converted box: [  1 109  46 276], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,496 - embedding_process - DEBUG - Box coordinates after boundary check: [1, 109, 46, 276]
2025-04-16 17:26:00,496 - embedding_process - DEBUG - Extracting crop from coordinates: y=109:276, x=1:46
2025-04-16 17:26:00,497 - embedding_process - DEBUG - Crop shape: (167, 45, 3), dtype: uint8
2025-04-16 17:26:00,497 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_31_0.00_crop.png
2025-04-16 17:26:00,498 - embedding_process - INFO - Generating embeddings for detection tesseract_0_31_0.00...
2025-04-16 17:26:00,498 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,498 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,498 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 167, 45]), Type: torch.float32
2025-04-16 17:26:00,498 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,498 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,520 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,521 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,521 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,521 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,522 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 167, 45]), Type: torch.float32
2025-04-16 17:26:00,522 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,522 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,543 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,543 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,543 - embedding_process - DEBUG -     Sample: [-0.0580187551677227, 0.04600237309932709, -0.0075357770547270775]...
2025-04-16 17:26:00,544 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,544 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,544 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 167, 45]), Type: torch.float32
2025-04-16 17:26:00,544 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,544 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,561 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,562 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,562 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,563 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_31_0.00_embeddings.json
2025-04-16 17:26:00,564 - embedding_process - INFO - 
Processing detection 33/36: tesseract_0_32_0.00
2025-04-16 17:26:00,564 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,564 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,564 - embedding_process - DEBUG - Converted box: [748 222 908 325], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,564 - embedding_process - DEBUG - Box coordinates after boundary check: [748, 222, 908, 325]
2025-04-16 17:26:00,564 - embedding_process - DEBUG - Extracting crop from coordinates: y=222:325, x=748:908
2025-04-16 17:26:00,565 - embedding_process - DEBUG - Crop shape: (103, 160, 3), dtype: uint8
2025-04-16 17:26:00,566 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_32_0.00_crop.png
2025-04-16 17:26:00,566 - embedding_process - INFO - Generating embeddings for detection tesseract_0_32_0.00...
2025-04-16 17:26:00,566 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,566 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,566 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 103, 160]), Type: torch.float32
2025-04-16 17:26:00,567 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,567 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,588 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,589 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,589 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,589 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,589 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 103, 160]), Type: torch.float32
2025-04-16 17:26:00,589 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,590 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,611 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,612 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,612 - embedding_process - DEBUG -     Sample: [0.019259165972471237, 0.018953628838062286, -0.009304081089794636]...
2025-04-16 17:26:00,612 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,612 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,612 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 103, 160]), Type: torch.float32
2025-04-16 17:26:00,613 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,613 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,629 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,630 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,630 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,632 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_32_0.00_embeddings.json
2025-04-16 17:26:00,632 - embedding_process - INFO - 
Processing detection 34/36: tesseract_0_33_0.00
2025-04-16 17:26:00,632 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,632 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,633 - embedding_process - DEBUG - Converted box: [230 169 305 233], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,633 - embedding_process - DEBUG - Box coordinates after boundary check: [230, 169, 305, 233]
2025-04-16 17:26:00,633 - embedding_process - DEBUG - Extracting crop from coordinates: y=169:233, x=230:305
2025-04-16 17:26:00,633 - embedding_process - DEBUG - Crop shape: (64, 75, 3), dtype: uint8
2025-04-16 17:26:00,634 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_33_0.00_crop.png
2025-04-16 17:26:00,634 - embedding_process - INFO - Generating embeddings for detection tesseract_0_33_0.00...
2025-04-16 17:26:00,634 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,634 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,634 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 64, 75]), Type: torch.float32
2025-04-16 17:26:00,634 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,634 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,654 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,655 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,655 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,655 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,656 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 64, 75]), Type: torch.float32
2025-04-16 17:26:00,656 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,656 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,677 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,677 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,677 - embedding_process - DEBUG -     Sample: [-0.04290109500288963, 0.03950941935181618, 0.015617131255567074]...
2025-04-16 17:26:00,677 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,677 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,678 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 64, 75]), Type: torch.float32
2025-04-16 17:26:00,678 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,678 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,693 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,694 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,694 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,696 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_33_0.00_embeddings.json
2025-04-16 17:26:00,696 - embedding_process - INFO - 
Processing detection 35/36: tesseract_0_34_0.00
2025-04-16 17:26:00,696 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,696 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,697 - embedding_process - DEBUG - Converted box: [184 226 336 286], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,697 - embedding_process - DEBUG - Box coordinates after boundary check: [184, 226, 336, 286]
2025-04-16 17:26:00,697 - embedding_process - DEBUG - Extracting crop from coordinates: y=226:286, x=184:336
2025-04-16 17:26:00,697 - embedding_process - DEBUG - Crop shape: (60, 152, 3), dtype: uint8
2025-04-16 17:26:00,698 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_34_0.00_crop.png
2025-04-16 17:26:00,698 - embedding_process - INFO - Generating embeddings for detection tesseract_0_34_0.00...
2025-04-16 17:26:00,698 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,698 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,698 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 60, 152]), Type: torch.float32
2025-04-16 17:26:00,698 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,699 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,720 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,721 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,721 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,721 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,721 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 60, 152]), Type: torch.float32
2025-04-16 17:26:00,721 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,721 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,743 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,743 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,743 - embedding_process - DEBUG -     Sample: [0.008257858455181122, -0.020362358540296555, 0.019272828474640846]...
2025-04-16 17:26:00,743 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,743 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,743 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 60, 152]), Type: torch.float32
2025-04-16 17:26:00,743 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,744 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,760 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,761 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,761 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,763 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_34_0.00_embeddings.json
2025-04-16 17:26:00,763 - embedding_process - INFO - 
Processing detection 36/36: tesseract_0_35_0.00
2025-04-16 17:26:00,763 - embedding_process - DEBUG - Original box type: <class 'torch.Tensor'>
2025-04-16 17:26:00,763 - embedding_process - DEBUG - Box tensor - Type: torch.float32, Shape: torch.Size([4]), Device: cuda:0
2025-04-16 17:26:00,763 - embedding_process - DEBUG - Converted box: [535 268 641 329], Type: <class 'numpy.ndarray'>
2025-04-16 17:26:00,763 - embedding_process - DEBUG - Box coordinates after boundary check: [535, 268, 641, 329]
2025-04-16 17:26:00,763 - embedding_process - DEBUG - Extracting crop from coordinates: y=268:329, x=535:641
2025-04-16 17:26:00,764 - embedding_process - DEBUG - Crop shape: (61, 106, 3), dtype: uint8
2025-04-16 17:26:00,764 - embedding_process - DEBUG - Saved crop to: results/embeddings_full/tesseract_0_35_0.00_crop.png
2025-04-16 17:26:00,765 - embedding_process - INFO - Generating embeddings for detection tesseract_0_35_0.00...
2025-04-16 17:26:00,765 - embedding_process - INFO -   Generating embeddings with clip...
2025-04-16 17:26:00,765 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,765 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 61, 106]), Type: torch.float32
2025-04-16 17:26:00,765 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,765 - embedding_process - DEBUG - Calling generate_embedding for clip
2025-04-16 17:26:00,785 - embedding_process - ERROR -     Error with clip: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,786 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,786 - embedding_process - INFO -   Generating embeddings with vit...
2025-04-16 17:26:00,786 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,787 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 61, 106]), Type: torch.float32
2025-04-16 17:26:00,787 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,787 - embedding_process - DEBUG - Calling generate_embedding for vit
2025-04-16 17:26:00,808 - embedding_process - DEBUG - Converting embedding to list for JSON serialization
2025-04-16 17:26:00,808 - embedding_process - INFO -     Generated vit embedding of length 768
2025-04-16 17:26:00,808 - embedding_process - DEBUG -     Sample: [0.01996523141860962, 0.03318939357995987, -0.044068727642297745]...
2025-04-16 17:26:00,808 - embedding_process - INFO -   Generating embeddings with resnet50...
2025-04-16 17:26:00,808 - embedding_process - DEBUG - Converting crop to tensor for debugging
2025-04-16 17:26:00,808 - embedding_process - DEBUG - Crop tensor - Shape: torch.Size([3, 61, 106]), Type: torch.float32
2025-04-16 17:26:00,808 - embedding_process - DEBUG - Crop tensor moved to device: cuda:0
2025-04-16 17:26:00,809 - embedding_process - DEBUG - Calling generate_embedding for resnet50
2025-04-16 17:26:00,824 - embedding_process - ERROR -     Error with resnet50: Got unsupported ScalarType BFloat16
2025-04-16 17:26:00,825 - embedding_process - ERROR -     Traceback: Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/process_embeddings.py", line 396, in main
    crop_emb = embedding_generator.generate_embedding(crop, model_type)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/e2e_pipeline_v2/modules/embedding/generator.py", line 157, in generate_embedding
    embedding = embedding.cpu().numpy().flatten()
                ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Got unsupported ScalarType BFloat16

2025-04-16 17:26:00,825 - embedding_process - DEBUG - Preparing detection info for JSON serialization
2025-04-16 17:26:00,826 - embedding_process - INFO -   Saved embeddings to results/embeddings_full/tesseract_0_35_0.00_embeddings.json
2025-04-16 17:26:00,827 - embedding_process - INFO - Embedding generation completed in 2.56 seconds
2025-04-16 17:26:00,827 - embedding_process - INFO - 
Saved summary to results/embeddings_full/tesseract_embeddings_summary.json
2025-04-16 17:26:00,827 - embedding_process - INFO - Total number of processed items: 36
2025-04-16 17:26:00,827 - embedding_process - INFO - 
== Performance Summary ==
2025-04-16 17:26:00,827 - embedding_process - INFO - Total execution time: 17.95 seconds
2025-04-16 17:26:00,827 - embedding_process - INFO - Pipeline processing: 6.94 seconds (38.6%)
2025-04-16 17:26:00,828 - embedding_process - INFO - Embedding generation: 2.56 seconds (14.3%)
2025-04-16 17:26:00,828 - embedding_process - INFO - Processed 1 images with 36 detections
2025-04-16 17:26:00,828 - embedding_process - INFO - Average time per detection: 0.07 seconds
