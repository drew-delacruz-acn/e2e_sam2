2025-04-17 21:38:03,098 - INFO - Logging initialized. Log file: ./comparison_results/logs/comparison_20250417_213803.log
2025-04-17 21:38:03,098 - INFO - Python version: 3.12.9 | packaged by Anaconda, Inc. | (main, Feb  6 2025, 18:56:27) [GCC 11.2.0]
2025-04-17 21:38:03,099 - INFO - PyTorch version: 2.6.0+cu124
2025-04-17 21:38:03,099 - INFO - OpenCV version: 4.11.0
2025-04-17 21:38:03,099 - INFO - Arguments: {'data_dir': '../data/davis-2017/DAVIS/', 'splits_dir': './dataset_splits', 'pretrained_checkpoint': '../checkpoints/sam2.1_hiera_large.pt', 'finetuned_checkpoint': './models/sam2_finetuned_best.torch', 'model_cfg': '../configs/sam2.1/sam2.1_hiera_l.yaml', 'output_dir': './comparison_results', 'num_samples': -1, 'debug': False}
2025-04-17 21:38:03,141 - INFO - Using CUDA device: Tesla V100-SXM2-16GB
2025-04-17 21:38:03,141 - INFO - CUDA memory allocated: 0.00 GB
2025-04-17 21:38:03,142 - INFO - Loaded 17 samples from ./dataset_splits/val.json
2025-04-17 21:38:03,142 - INFO - 
Evaluating pre-trained model...
2025-04-17 21:38:03,142 - INFO - Loading model from ../checkpoints/sam2.1_hiera_large.pt
2025-04-17 21:38:06,545 - INFO - Loaded checkpoint sucessfully
2025-04-17 21:38:07,009 - INFO - Model loaded successfully
2025-04-17 21:38:07,036 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:07,140 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:07,458 - INFO - Image embeddings computed.
2025-04-17 21:38:07,465 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00075.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:07,467 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:07,491 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:07,520 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:07,557 - INFO - Image embeddings computed.
2025-04-17 21:38:07,700 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00076.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:07,701 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:07,725 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:07,735 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:07,772 - INFO - Image embeddings computed.
2025-04-17 21:38:07,914 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00029.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:07,915 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:07,940 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:07,949 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:07,986 - INFO - Image embeddings computed.
2025-04-17 21:38:08,129 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00062.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:08,130 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:08,154 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:08,163 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:08,200 - INFO - Image embeddings computed.
2025-04-17 21:38:08,343 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00051.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:08,344 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:08,368 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:08,374 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:08,412 - INFO - Image embeddings computed.
2025-04-17 21:38:08,554 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00038.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:08,555 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:08,579 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:08,588 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:08,626 - INFO - Image embeddings computed.
2025-04-17 21:38:08,768 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00005.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:08,769 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:08,793 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:08,803 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:08,840 - INFO - Image embeddings computed.
2025-04-17 21:38:08,982 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00002.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:08,983 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:09,008 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:09,017 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:09,054 - INFO - Image embeddings computed.
2025-04-17 21:38:09,196 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00061.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:09,197 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:09,222 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:09,231 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:09,268 - INFO - Image embeddings computed.
2025-04-17 21:38:09,411 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00003.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:09,412 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:09,436 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:09,445 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:09,483 - INFO - Image embeddings computed.
2025-04-17 21:38:09,625 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00049.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:09,626 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:09,650 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:09,659 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:09,697 - INFO - Image embeddings computed.
2025-04-17 21:38:09,839 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00035.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:09,840 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:09,864 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:09,873 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:09,910 - INFO - Image embeddings computed.
2025-04-17 21:38:10,053 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00053.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:10,054 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:10,078 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:10,087 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:10,127 - INFO - Image embeddings computed.
2025-04-17 21:38:10,267 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00026.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:10,268 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:10,292 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:10,299 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:10,336 - INFO - Image embeddings computed.
2025-04-17 21:38:10,479 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00048.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:10,480 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:10,505 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:10,510 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:10,548 - INFO - Image embeddings computed.
2025-04-17 21:38:10,690 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00063.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:10,691 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:10,716 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:10,721 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:10,759 - INFO - Image embeddings computed.
2025-04-17 21:38:10,901 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00080.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:10,902 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:10,903 - ERROR - Fatal error in main execution:
2025-04-17 21:38:10,903 - ERROR - No valid results obtained from evaluation
2025-04-17 21:38:10,903 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 308, in main
    pretrained_metrics, pretrained_stds, pretrained_results, pretrained_errors = evaluate_model(
                                                                                 ^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 244, in evaluate_model
    raise ValueError("No valid results obtained from evaluation")
ValueError: No valid results obtained from evaluation

