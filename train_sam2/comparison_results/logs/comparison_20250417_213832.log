2025-04-17 21:38:32,197 - INFO - Logging initialized. Log file: ./comparison_results/logs/comparison_20250417_213832.log
2025-04-17 21:38:32,197 - INFO - Python version: 3.12.9 | packaged by Anaconda, Inc. | (main, Feb  6 2025, 18:56:27) [GCC 11.2.0]
2025-04-17 21:38:32,197 - INFO - PyTorch version: 2.6.0+cu124
2025-04-17 21:38:32,197 - INFO - OpenCV version: 4.11.0
2025-04-17 21:38:32,197 - INFO - Arguments: {'data_dir': '../data/davis-2017/DAVIS/', 'splits_dir': './dataset_splits', 'pretrained_checkpoint': '../checkpoints/sam2.1_hiera_large.pt', 'finetuned_checkpoint': './models/sam2_finetuned_best.torch', 'model_cfg': '../configs/sam2.1/sam2.1_hiera_l.yaml', 'output_dir': './comparison_results', 'num_samples': -1, 'debug': True}
2025-04-17 21:38:32,240 - INFO - Using CUDA device: Tesla V100-SXM2-16GB
2025-04-17 21:38:32,240 - INFO - CUDA memory allocated: 0.00 GB
2025-04-17 21:38:32,240 - INFO - Loaded 17 samples from ./dataset_splits/val.json
2025-04-17 21:38:32,240 - INFO - 
Evaluating pre-trained model...
2025-04-17 21:38:32,240 - INFO - Loading model from ../checkpoints/sam2.1_hiera_large.pt
2025-04-17 21:38:35,648 - INFO - Loaded checkpoint sucessfully
2025-04-17 21:38:36,110 - INFO - Model loaded successfully
2025-04-17 21:38:36,140 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:36,239 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:36,553 - INFO - Image embeddings computed.
2025-04-17 21:38:36,560 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00075.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:36,562 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:36,587 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:36,616 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:36,651 - INFO - Image embeddings computed.
2025-04-17 21:38:36,797 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00076.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:36,798 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:36,823 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:36,832 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:36,866 - INFO - Image embeddings computed.
2025-04-17 21:38:37,011 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00029.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:37,012 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:37,037 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:37,046 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:37,081 - INFO - Image embeddings computed.
2025-04-17 21:38:37,226 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00062.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:37,226 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:37,251 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:37,260 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:37,295 - INFO - Image embeddings computed.
2025-04-17 21:38:37,440 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00051.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:37,440 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:37,465 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:37,474 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:37,509 - INFO - Image embeddings computed.
2025-04-17 21:38:37,654 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00038.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:37,655 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:37,680 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:37,689 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:37,723 - INFO - Image embeddings computed.
2025-04-17 21:38:37,868 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00005.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:37,869 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:37,894 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:37,903 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:37,938 - INFO - Image embeddings computed.
2025-04-17 21:38:38,083 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00002.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:38,084 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:38,108 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:38,117 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:38,152 - INFO - Image embeddings computed.
2025-04-17 21:38:38,297 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00061.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:38,298 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:38,323 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:38,332 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:38,367 - INFO - Image embeddings computed.
2025-04-17 21:38:38,512 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00003.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:38,513 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:38,539 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:38,549 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:38,584 - INFO - Image embeddings computed.
2025-04-17 21:38:38,728 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00049.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:38,729 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:38,754 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:38,763 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:38,798 - INFO - Image embeddings computed.
2025-04-17 21:38:38,943 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00035.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:38,944 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:38,969 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:38,978 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:39,013 - INFO - Image embeddings computed.
2025-04-17 21:38:39,157 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00053.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:39,158 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:39,183 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:39,192 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:39,227 - INFO - Image embeddings computed.
2025-04-17 21:38:39,372 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00026.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:39,373 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:39,398 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:39,407 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:39,442 - INFO - Image embeddings computed.
2025-04-17 21:38:39,587 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00048.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:39,588 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:39,612 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:39,621 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:39,656 - INFO - Image embeddings computed.
2025-04-17 21:38:39,801 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00063.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:39,802 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:39,827 - INFO - For numpy array image, we assume (HxWxC) format
2025-04-17 21:38:39,836 - INFO - Computing image embeddings for the provided image...
2025-04-17 21:38:39,871 - INFO - Image embeddings computed.
2025-04-17 21:38:40,016 - ERROR - Error processing object 0 in ../data/davis-2017/DAVIS/Annotations/480p/bear/00080.png: Tensors must have same number of dimensions: got 3 and 2
2025-04-17 21:38:40,017 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 207, in evaluate_model
    masks, scores, _ = predictor.predict(
                       ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 291, in predict
    masks, iou_predictions, low_res_masks = self._predict(
                                            ^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/sam2_image_predictor.py", line 406, in _predict
    sparse_embeddings, dense_embeddings = self.model.sam_prompt_encoder(
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 189, in forward
    point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/sam2/sam2/modeling/sam/prompt_encoder.py", line 91, in _embed_points
    labels = torch.cat([labels, padding_label], dim=1)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Tensors must have same number of dimensions: got 3 and 2

2025-04-17 21:38:40,017 - ERROR - Fatal error in main execution:
2025-04-17 21:38:40,017 - ERROR - No valid results obtained from evaluation
2025-04-17 21:38:40,018 - ERROR - Traceback (most recent call last):
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 308, in main
    pretrained_metrics, pretrained_stds, pretrained_results, pretrained_errors = evaluate_model(
                                                                                 ^^^^^^^^^^^^^^^
  File "/home/ubuntu/code/drew/experiments/e2e_sam2/train_sam2/compare_models.py", line 244, in evaluate_model
    raise ValueError("No valid results obtained from evaluation")
ValueError: No valid results obtained from evaluation

